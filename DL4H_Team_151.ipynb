{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "sfk8Zrul_E8V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Github Address and Getting the Project to Work Locally\n",
        "\n",
        "Due to file size limits, the project files (checkpoints and some preprocessed files) had to be uploaded to Google Drive. However, in order to reproduce the results of the project, you can access the necessary files through the following links:\n",
        "\n",
        "\n",
        "**Link to Google Drive with Trained Model and Preprocessed Files (Don't include all files due to licensing restrictions as well as not all models being ready at this time)**: https://drive.google.com/drive/folders/1EJgVV2Vx8gUM0TKJldBJjsT30oBROW1U?usp=drive_link\n",
        "\n",
        "**MIMIC-III v1.4**: Can be downloaded from  https://physionet.org/content/mimiciii/1.4/ with appropriate credential\n",
        "\n",
        "**Supplementary HADM (Hospital Admission IDs)**: These can be downloaded from the following link: https://github.com/jamesmullenbach/caml-mimic/tree/master/mimicdata/mimic3\n",
        "\n",
        "**GitHub Address**: https://github.com/SaadatUIUC/HiCu-ICD-UIUC-Evaluation\n",
        "\n",
        "**Setting up the Environment Locally**:\n",
        "\n",
        "For best experience setting up the project, I recommend **Anaconda**, which can be downloaded from the following link: https://www.anaconda.com/\n",
        "\n",
        "Ignore the original project `requirements.txt` as it didn't work in my observation. Instead, use the provided `environment.yml` file by executing the following command:\n",
        "\n",
        "`conda env create -f environment.yml`\n",
        "\n",
        "Once **MIMIC-III** and **.hadm_ids.csv** files are downloaded, follow the project README to place them in the appropriate location under the project's `data` directory. You will also need to create a `mimic` directory under the data directory.\n",
        "\n",
        "Once the project is stable and files are in location, activate the `conda activate hicu_env`environment and execute:\n",
        "\n",
        "`python preprocess_mimic.py`\n",
        "\n",
        "This should produce `.embed`, `.npy`, `.w2v` and `.csv` files in `mimic` directory.\n",
        "\n",
        "## Training Model\n",
        "\n",
        "Create a folder named `model` in the project root directory, at the same level where folders like `runs` and `data` also exist.\n",
        "\n",
        "The Google Drive link above contains some (due licensing issues) of the preprocessed files and model.\n",
        "\n",
        "However, if you intend to run the project yourself and train the models, you can use any of the models under the `runs` folder:\n",
        "\n",
        "For this experiment, I tried `MultiResCNN with HiCuA` and `RAC with HiCuA`. The relevant files would be `run_multirescnn_hicua.sh` and `run_rac_hicua.sh` if you use a UNIX-like system, or the files I added, `run_multirescnn_hicua.bat` and `run_rac_hicua.bat`, if you use a Windows environment. I also modified the selected files to make them easier to run by making the file hierarchy more self-contained.\n",
        "\n",
        "Keep in mind that for `run_rac_hicua.sh`, you need to adjust the `--gpu` parameter based on the number of GPUs you use to train.\n",
        "\n",
        "Once in your activated conda environment, you should be able to run the experiments in the root of the project directory like the following example:\n",
        "\n",
        "`runs\\run_multirescnn_hicua.bat`\n"
      ],
      "metadata": {
        "id": "tXi-n5WU7M_O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "The paper \"HiCu: Leveraging Hierarchy for Curriculum Learning in Automated ICD Coding\" by Weiming Ren et al. explores the use of curriculum learning to improve the automation of medical diagnosis code prediction from clinical notes. The authors focus on International Classification of Diseases (ICD) coding, a crucial multi-label classification task in healthcare that significantly affects clinical, epidemiological, and administrative functions.\n",
        "\n",
        "### What are ICD Codes?\n",
        "ICD codes are standardized tools used globally for coding various diagnoses, symptoms, and procedures documented in healthcare settings. They are integral to managing patient care, conducting epidemiological studies, and facilitating healthcare billing. The automation of ICD coding is aimed at improving efficiency and reducing the potential for errors in medical documentation.\n",
        "\n",
        "## Background of the Problem\n",
        "Automated ICD coding involves the classification of textual clinical documents into ICD codes, which are used globally to classify and record diagnoses, symptoms, and procedures. This coding is crucial for patient care tracking, epidemiological monitoring, and healthcare billing. The task is inherently complex due to the large number, specificity, and hierarchical structure of ICD codes. Accurately automating this process is challenging due to the nuanced and detailed information contained in clinical notes, the imbalanced distribution of codes (many codes are rarely used), and the requirement to correctly assign multiple codes to a single document.\n",
        "\n",
        "## Importance and Difficulty\n",
        "The accurate assignment of ICD codes enhances the efficiency of healthcare billing, improves the accuracy of health records, and supports robust health information exchange across systems. Misclassifications can lead to incorrect treatment plans, billing errors, and improper data recording, which can have serious repercussions for patient care and administrative processes.\n",
        "\n",
        "## State of the Art and Effectiveness\n",
        "Current state-of-the-art methods for automated ICD coding mostly rely on deep learning techniques, such as CNNs, RNNs, and transformers, which can effectively handle large volumes of text data. However, these methods often treat each code as an independent label, which can lead to inefficiencies and inaccuracies, particularly with rare codes. These models generally struggle with the hierarchical and imbalanced nature of the code set, leading to a lack of generalization in the prediction of less common codes.\n",
        "\n",
        "## What Did the Paper Propose?\n",
        "The paper presents the HiCu algorithm, which employs a novel approach by using a depth-wise decomposition of the label graph and a hyperbolic-embedding-based knowledge transfer mechanism to tackle the challenges posed by automated ICD coding. This method leverages the inherent structure of medical coding systems to improve model performance.\n",
        "\n",
        "## Innovations of the Method\n",
        "HiCu introduces a methodological innovation by applying hierarchical curriculum learning. By utilizing the structured nature of ICD codes, it provides a staged training approach that effectively combats the issues of imbalance and specificity, resulting in improved model generalization across a range of codes.\n",
        "\n",
        "## Evaluation of Model Efficacy Based on HiCu Learning Algorithm Enhancements\n",
        "In an assessment of the HiCu learning algorithm's impact on the MIMIC-III Full Code dataset, significant performance enhancements were reported. The metrics, averaged over 10 random runs and presented with standard deviations, demonstrate the algorithm's robustness. Re-evaluated baselines establish a foundation for comparing the performance enhancements brought by HiCu across various experimental setups. The results highlight the algorithm's ability to address the intricate challenges of multi-label classification within the domain of medical coding.\n",
        "\n",
        "- **LAAT Model Performance with HiCuA (Hyperbolic Correction Addition)**:\n",
        "  - **AUC Macro**: Increased from a baseline of 92.0% to **<u>94.8%</u>**, indicating a substantial impact from HiCuA.\n",
        "  - **AUC Micro**: Improved from 98.8% to <u>99.1%</u>, signifying fine-tuned predictive accuracy.\n",
        "  - **F1 Macro**: Rose from 9.7% to <u>10.2%</u>, showcasing the enhancement in identifying correct labels.\n",
        "  - **F1 Micro**: Remained consistent at <u>57.4%</u>, reflecting the model's stability after HiCuA integration.\n",
        "\n",
        "- **RAC Model Advancements with HiCuA and HiCuC**:\n",
        "  - **AUC Macro**: Improved scores from 93.0% to 94.3% with HiCuA and to <u>94.4%</u> with HiCuC, demonstrating effectiveness in top-ranked label prediction.\n",
        "  - **AUC Micro**: Score rose from 98.8% to <u>99.0%</u> with both HiCuA and HiCuC, denoting marginal yet positive changes.\n",
        "  - **F1 Macro**: Ascended from 7.9% to <u>8.4%</u> for both methodologies, reflecting improved overall label predictions.\n",
        "  - **F1 Micro**: Increased from 55.4% to <u>56.5%</u> with HiCuA and slightly to 55.8% with HiCuC, indicating better precision in the higher-ranked predictions.\n",
        "\n",
        "- **MultiResCNN Model Enhancements with HiCuA, HiCuC, HiCuA+ASL, and HiCuC+ASL**:\n",
        "  - **AUC Macro**: Exhibited growth from 91.2% to <u>94.7%</u> with HiCuA, to 94.6% with HiCuC, advancing further to 93.7% with HiCuA+ASL, and to 94.0% with HiCuC+ASL, highlighting the layered improvements across the model configurations.\n",
        "  - **AUC Micro**: Displayed gains from 98.7% to <u>99.1%</u> with both HiCuA and HiCuC, maintaining at 98.9% with both HiCuA+ASL and HiCuC+ASL, suggesting nuanced improvements in the model's ability to classify across a broad label spectrum.\n",
        "  - **F1 Macro**: Showed an uplift from the baseline of 8.6% to 9.2% with HiCuA, 9.3% with HiCuC, and notable peaks at 11.4% with HiCuA+ASL and **<u>11.5%</u>** with HiCuC+ASL, evidencing the HiCu algorithm's strength in macro-level label discernment.\n",
        "  - **F1 Micro**: Noted an enhancement from 56.2% to 56.7% with HiCuA, holding at 56.6% with HiCuC, and reaching **<u>57.6%</u>** with HiCuA+ASL and 57.4% with HiCuC+ASL, affirming the precision in identifying the most relevant labels.\n",
        "\n",
        "The empirical data reviewed suggest that the implementation of the HiCu algorithm has significantly refined the efficacy of existing models in the domain of multi-label ICD code classification, particularly enhancing the precision and recall of infrequent code predictions.\n",
        "\n",
        "## Contribution to the Research Regime\n",
        "The research presented in the HiCu paper is substantial, offering a novel method for utilizing curriculum learning tailored to hierarchical data structures. This method holds potential for applications in healthcare and other domains involving structured prediction tasks. The paper's findings significantly contribute to the evolution of automated medical coding systems, heralding more reliable and efficient healthcare services."
      ],
      "metadata": {
        "id": "MQ0sNuMePBXx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Scope of Reproducibility\n",
        "\n",
        "The purpose of this section is to outline the specific aspects of the original study \"HiCu: Leveraging Hierarchy for Curriculum Learning in Automated ICD Coding\" by Weiming Ren et al. that I aim to reproduce. Due to resource limitations, this reproducibility effort will focus on testing selected hypotheses using a subset of the models discussed in the paper.\n",
        "\n",
        "### Selected Hypotheses and Corresponding Experiments\n",
        "\n",
        "- **Hypothesis 1: Evaluating MultiResCNN with HiCuA**\n",
        "  - **Claim from the Paper**: The application of the HiCuA (Hyperbolic Correction Addition) significantly enhances the MultiResCNN model's performance in terms of both AUC and F1 scores. Specifically, it reports an improvement in AUC Macro from a baseline of 91.2% to 94.7%, and in AUC Micro from 98.7% to 99.1%. Additionally, it notes an increase in F1 Macro from 8.6% to 9.2%, and F1 Micro from 56.2% to 56.7%.\n",
        "  - **Experiment**: I have successfully replicated the `MultiResCNN_HiCuA` model on the MIMIC-III dataset and evaluated its performance. The outcomes, specifically AUC Macro, AUC Micro, F1 Macro, and F1 Micro, have been compared against the metrics reported in the original study to assess the reproducibility of the claimed improvements.\n",
        "\n",
        "- **Hypothesis 2: Evaluating RAC with HiCuA**\n",
        "  - **Claim from the Paper**: The HiCuA method significantly enhances the predictive accuracy and performance of the RAC reader model, especially in terms of handling rare ICD codes. The paper reports an improvement in AUC Macro from a baseline of 93.0% to 94.3%, and in AUC Micro from 98.8% to 99.0%. Additionally, it notes an increase in F1 Macro from 7.9% to 8.4% and an improvement in F1 Micro from 55.4% to 56.5%.\n",
        "  - **Experiment**: The `RACReader_HiCuA` model is currently in the training phase, which is proving to be very resource-intensive. Once the training is complete, critical performance metrics—including AUC Macro, AUC Micro, F1 Macro, and F1 Micro—will be evaluated and compared against the results reported in the original paper. This analysis will help verify the claimed enhancements in predictive accuracy, with a specific focus on the model's ability to accurately predict rare ICD codes.\n",
        "\n",
        "- **Hypothesis 3: Evaluating LAAT with HiCuA + ASL**\n",
        "  - **Claim from the Paper**: Implementing HiCuA + ASL with the LAAT model significantly enhances the model's performance in terms of both AUC and F1 scores. The paper reports an improvement in AUC Macro from a baseline of 92.0% to 94.8%, and in AUC Micro from 98.8% to 99.1%. Additionally, it notes an increase in F1 Macro from 9.7% to 10.2%, while F1 Micro remains unchanged at 57.4%.\n",
        "  - **Experiment**: Plans are in place to run the `LAAT_HiCuA+ASL` model to assess its effectiveness on these specified metrics once sufficient resources are available. This experiment aims to validate the reported enhancements and further explore the model's performance consistency, particularly in its handling of rare ICD codes.\n",
        "\n",
        "### Anticipated Challenges\n",
        "\n",
        "Reproducing the models described in \"HiCu: Leveraging Hierarchy for Curriculum Learning in Automated ICD Coding\" has presented several challenges, which are crucial to document for understanding the scope and potential limitations of this reproducibility effort.\n",
        "\n",
        "#### Hardware Limitations\n",
        "- **GPU Resources**: The original study utilized a high-end setup with at least 4 NVIDIA Tesla V100 GPUs. In contrast, I am working with a single 4090 GPU. This substantial reduction in computational power has necessitated adjustments in the code to accommodate a less powerful system without compromising the integrity of the results.\n",
        "\n",
        "#### Software and Library Compatibility\n",
        "- **Library Mismatches**: The original implementation was designed for a Unix-like environment optimized for multi-GPU support, which has required careful adaptation to run effectively on my available hardware. Additionally, the paper used older versions of libraries and dependencies, some of which are now deprecated. Establishing a stable environment that mimics the original settings as closely as possible involved troubleshooting and configuration.\n",
        "- **Code Adaptation**: Adapting the scripts for a single GPU setup in Windows environment and ensuring compatibility with current software versions has been a meticulous and time-consuming process.\n",
        "\n",
        "#### Experimental Time Constraints\n",
        "- **Extended Training Times**: Some models, notably the RAC with HiCuA, have taken an inordinate amount of time to train — over 80 hours at the time of this writing. This has implications for the feasibility of conducting all planned experiments within a reasonable timeframe.\n",
        "- **Scope of Study Limitation**: Given these time constraints and resource limitations, I have decided to limit the scope of this study to three specific hypotheses:\n",
        "  - Evaluating MultiResCNN with HiCuA\n",
        "  - Evaluating RAC with HiCuA\n",
        "  - Evaluating LAAT with HiCuA + ASL\n",
        "- This approach allows for a focused and manageable replication effort, covering:\n",
        "  - 100% of the claims made about improvements to the LAAT model.\n",
        "  - 50% of the claims regarding algorithmic enhancements to the RAC model.\n",
        "  - 25% of the performance gains claimed for the MultiResCNN model.\n",
        "\n",
        "#### Potential Expansion\n",
        "- If time and resources permit, I may consider expanding the scope to include additional hypotheses. The original paper outlines a total of seven hypotheses (1 for LAAT, 2 for RAC, and 4 for MultiResCNN). Currently, plans are in place to cover one hypothesis each for LAAT and RAC, and one for MultiResCNN.\n",
        "\n",
        "This documentation of challenges not only highlights the difficulties faced in replicating the study but also underscores the adaptability required to overcome these hurdles. The insights gained from addressing these challenges will be invaluable in interpreting the outcomes of the reproducibility tests and understanding any deviations from the original results.\n"
      ],
      "metadata": {
        "id": "uygL9tTPSVHB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# no code is required for this section\n",
        "\n",
        "from google.colab import drive\n",
        "import cv2\n",
        "\n",
        "'''\n",
        "if you want to use an image outside this notebook for explanaition,\n",
        "you can upload it to your google drive and show it with OpenCV or matplotlib\n",
        "'''\n",
        "# mount this notebook to your google drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# define dirs to workspace and data\n",
        "img_path = '/content/drive/My Drive/Fig_2.png'\n",
        "\n",
        "img = cv2.imread(img_path)\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert from BGR to RGB"
      ],
      "metadata": {
        "id": "rRksCB1vbYwJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Methodology\n",
        "\n",
        "This section outlines the methodology underlying my project, detailing the approach taken to adapt and test the hypotheses originally presented in the paper \"HiCu: Leveraging Hierarchy for Curriculum Learning in Automated ICD Coding.\" The initial implementation involved addressing compatibility issues with the packages and adapting the provided `.sh` scripts to `.bat` files. This adaptation was necessary to accommodate the Windows environment on the dedicated training machine, which is also being used to test the hypotheses. The conversion from `.sh` to `.bat` was essential because `.sh` scripts are typically utilized in UNIX-like systems, whereas `.bat` files are native to the Windows OS, ensuring compatibility and effective execution.\n",
        "\n",
        "Primary testing efforts are currently being conducted outside of the Google Colab environment. However, efforts are underway to adapt and stabilize the code for potential use in Google Colab.\n",
        "\n",
        "Additionally, I will document and provide the steps taken on the dedicated machine, from preprocessing to training, and include the relevant codes and logs. This will ensure a comprehensive understanding of the process and enable replication or review of the methods and results."
      ],
      "metadata": {
        "id": "xWAHJ_1CdtaA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "# packages specified in the preprocess_mimic3.py of HICU-ICD paper\n",
        "import pandas as pd\n",
        "from collections import Counter, defaultdict\n",
        "import csv\n",
        "import operator\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "yu61Jp1xrnKk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data\n",
        "\n",
        "### Data descriptions\n",
        "\n",
        "This section provides detailed information about the data used to reproduce the experiments from the original paper \"HiCu: Leveraging Hierarchy for Curriculum Learning in Automated ICD Coding.\" It covers the data source, basic statistics, processing steps, and illustrations of the processed data.\n",
        "\n",
        "### Source of the Data\n",
        "\n",
        "The primary dataset for this project is the MIMIC-III version 1.4 (Medical Information Mart for Intensive Care III) database. This extensive and publicly accessible database contains de-identified health-related data associated with over forty thousand patients who were admitted to critical care units of the Beth Israel Deaconess Medical Center between 2001 and 2012.\n",
        "\n",
        "- **Data Link**: [Access the MIMIC-III Clinical Database](https://physionet.org/content/mimiciii/1.4/)\n",
        "- **Direct Link to Data**: https://physionet.org/content/mimiciii/1.4/\n",
        "\n",
        "Supplementary `*_hadm_ids.csv` files, which contain unique identifiers for hospital admissions, are utilized to ensure that the data for analysis precisely corresponds to specific patient stays. This facilitates accurate matching of clinical notes to their respective admissions, crucial for the integrity of the data used in my experiments.\n",
        "\n",
        "- **Supplementary Data Link**: [MIMIC-III Hospital Admission IDs](https://github.com/jamesmullenbach/caml-mimic/tree/master/mimicdata/mimic3)\n",
        "- **Direct Link to Supplementary Data**: https://github.com/jamesmullenbach/caml-mimic/tree/master/mimicdata/mimic3\n",
        "\n",
        "Together, these resources ensure a comprehensive dataset that supports the experimental replication and validation of the selected hypotheses stated in the original study.\n",
        "\n",
        "### Statistics:\n",
        "- **Unique ICD-9 Codes**: The log shows there are <u>8,994</u> unique ICD-9 codes in the dataset. This reflects the diversity of diagnoses and procedures captured in the MIMIC-III database.\n",
        "- **Document Count and Tokens**: A total of <u>2,083,180</u> clinical notes were processed, with a staggering <u>92,868,012</u> tokens, indicating a vast amount of textual data.\n",
        "- **Hospital Admissions and Patients**: There were data for <u>52,726</u> unique hospital admissions (HADM_ID) and <u>41,127</u> unique subjects (SUBJECT_ID).\n",
        "\n",
        "### Data Processing:\n",
        "- **Concatenation and Filtering**: The logs show concatenating clinical notes with their corresponding ICD codes and filtering operations to align medical records correctly. This ensures that each clinical note is accurately associated with the correct medical coding.\n",
        "- **Rare Term Removal**: During vocabulary building, terms that were too rare (appearing in less than a threshold frequency) were removed, narrowing down the vocabulary to <u>51,919</u> terms from an initial <u>140,796</u>. This step is crucial for focusing the model's training on relevant terms and avoiding overfitting on noise.\n",
        "- **Data Split**: The dataset was split into training, development, and testing sets, as indicated by the log lines for `train`, `dev`, and `test`. This is essential for training models in a machine learning setup, allowing for proper evaluation and testing without leakage of information between the phases.\n",
        "\n",
        "### Preprocessing Execution Log\n",
        "\n",
        "This section presents the execution log of the `preprocess_mimic3.py` script, which processes and prepares the MIMIC-III dataset for further analysis. The script was executed on a dedicated machine and involved tasks such as parsing clinical notes, linking them to ICD codes, and generating word embeddings. Below is the log detailing each step and its output.\n",
        "\n",
        "```\n",
        "unique ICD9 code: 8994\n",
        "processing notes file\n",
        "writing to ./data/mimic3/disch_full.csv\n",
        "2083180it [04:25, 7842.26it/s]\n",
        "sys:1: DtypeWarning: Columns (2) have mixed types.Specify dtype option on import or set low_memory=False.\n",
        "CONCATENATING\n",
        "0 done\n",
        "10000 done\n",
        "20000 done\n",
        "30000 done\n",
        "40000 done\n",
        "50000 done\n",
        "num types 150855 num tokens 92868012\n",
        "HADM_ID: 52726\n",
        "SUBJECT_ID: 41127\n",
        "SPLITTING\n",
        "0 read\n",
        "10000 read\n",
        "20000 read\n",
        "30000 read\n",
        "40000 read\n",
        "50000 read\n",
        "reading in data...\n",
        "removing rare terms\n",
        "51919 terms qualify out of 140796 total\n",
        "writing output\n",
        "reading in data...\n",
        "removing rare terms\n",
        "51919 terms qualify out of 140796 total\n",
        "writing output\n",
        "building word2vec vocab on ./data/mimic3/disch_full.csv...\n",
        "training...\n",
        "writing embeddings to ./data/mimic3/processed_full_100.w2v\n",
        "100%|████████████████████████████████████████████████████████████████████████| 51919/51919 [00:00<00:00, 266210.36it/s]\n",
        "building word2vec vocab on ./data/mimic3/disch_full.csv...\n",
        "training...\n",
        "writing embeddings to ./data/mimic3/processed_full_300.w2v\n",
        "100%|████████████████████████████████████████████████████████████████████████| 51919/51919 [00:00<00:00, 230729.20it/s]\n",
        "train\n",
        "dev\n",
        "test\n",
        "```"
      ],
      "metadata": {
        "id": "2NbPHUTMbkD3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Illustrations\n",
        "\n",
        "The image illustrates a structured approach to automating ICD coding by leveraging a hierarchical model. At the first level, broad categories of diseases are defined by ranges of ICD codes. The subsequent third level is more granular, where diagnosis codes are described by a triplet of integers, and procedure codes are delineated by double digits. Levels four and five further refine the classification, featuring ICD codes with precision up to one and two decimal points, respectively. This granularity enables more detailed disease categorization. Notably, some codes, particularly under the range of 740-759 and all procedure codes, diverge from the traditional ICD structure, which includes continuous code ranges at the second level. To maintain consistency within the model, an intermediary level using identical start and end points for the code range has been introduced, as depicted by paths B and C. Additionally, in instances where the dataset labels are either whole integer codes or codes with a single decimal, duplication occurs in the fourth and fifth levels to complete the code tree structure, exemplified by paths D and E in the figure."
      ],
      "metadata": {
        "id": "4CBEhDPYGERc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(img)\n",
        "plt.axis('off')  # Turn off axis numbers and ticks\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CniCffutGCPb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implementation of Data Preprocessing\n",
        "\n",
        "**Currently the code is not optimized to run in Google Collab, and it doesn't need to as the preprocessing is already completed, but I aim to address this in coming days.**"
      ],
      "metadata": {
        "id": "yD9RSL-TkjOm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "from collections import Counter, defaultdict\n",
        "import csv\n",
        "import operator\n",
        "from utils.options import args\n",
        "from utils.utils import build_vocab, word_embeddings, fasttext_embeddings, gensim_to_fasttext_embeddings, gensim_to_embeddings, \\\n",
        "    reformat, write_discharge_summaries, concat_data, split_data\n",
        "\n",
        "\n",
        "\n",
        "Y = 'full'\n",
        "notes_file = '%s/NOTEEVENTS.csv' % args.MIMIC_3_DIR\n",
        "\n",
        "# step 1: process code-related files\n",
        "dfproc = pd.read_csv('%s/PROCEDURES_ICD.csv' % args.MIMIC_3_DIR)\n",
        "dfdiag = pd.read_csv('%s/DIAGNOSES_ICD.csv' % args.MIMIC_3_DIR)\n",
        "\n",
        "dfdiag['absolute_code'] = dfdiag.apply(lambda row: str(reformat(str(row[4]), True)), axis=1)\n",
        "dfproc['absolute_code'] = dfproc.apply(lambda row: str(reformat(str(row[4]), False)), axis=1)\n",
        "\n",
        "dfcodes = pd.concat([dfdiag, dfproc])\n",
        "\n",
        "\n",
        "dfcodes.to_csv('%s/ALL_CODES.csv' % args.MIMIC_3_DIR, index=False,\n",
        "           columns=['ROW_ID', 'SUBJECT_ID', 'HADM_ID', 'SEQ_NUM', 'absolute_code'],\n",
        "           header=['ROW_ID', 'SUBJECT_ID', 'HADM_ID', 'SEQ_NUM', 'ICD9_CODE'])\n",
        "\n",
        "df = pd.read_csv('%s/ALL_CODES.csv' % args.MIMIC_3_DIR, dtype={\"ICD9_CODE\": str})\n",
        "print(\"unique ICD9 code: {}\".format(len(df['ICD9_CODE'].unique())))\n",
        "\n",
        "# step 2: process notes\n",
        "min_sentence_len = 3\n",
        "disch_full_file = write_discharge_summaries(\"%s/disch_full.csv\" % args.MIMIC_3_DIR, min_sentence_len, '%s/NOTEEVENTS.csv' % (args.MIMIC_3_DIR))\n",
        "\n",
        "\n",
        "df = pd.read_csv('%s/disch_full.csv' % args.MIMIC_3_DIR)\n",
        "\n",
        "df = df.sort_values(['SUBJECT_ID', 'HADM_ID'])\n",
        "\n",
        "# step 3: filter out the codes that not emerge in notes\n",
        "hadm_ids = set(df['HADM_ID'])\n",
        "with open('%s/ALL_CODES.csv' % args.MIMIC_3_DIR, 'r') as lf:\n",
        "    with open('%s/ALL_CODES_filtered.csv' % args.MIMIC_3_DIR, 'w', newline='') as of:\n",
        "        w = csv.writer(of)\n",
        "        w.writerow(['SUBJECT_ID', 'HADM_ID', 'ICD9_CODE', 'ADMITTIME', 'DISCHTIME'])\n",
        "        r = csv.reader(lf)\n",
        "        #header\n",
        "        next(r)\n",
        "        for i,row in enumerate(r):\n",
        "            hadm_id = int(row[2])\n",
        "            #print(hadm_id)\n",
        "            #break\n",
        "            if hadm_id in hadm_ids:\n",
        "                w.writerow(row[1:3] + [row[-1], '', ''])\n",
        "\n",
        "dfl = pd.read_csv('%s/ALL_CODES_filtered.csv' % args.MIMIC_3_DIR, index_col=None)\n",
        "\n",
        "dfl = dfl.sort_values(['SUBJECT_ID', 'HADM_ID'])\n",
        "dfl.to_csv('%s/ALL_CODES_filtered.csv' % args.MIMIC_3_DIR, index=False)\n",
        "\n",
        "sorted_file = '%s/disch_full.csv' % args.MIMIC_3_DIR\n",
        "df.to_csv(sorted_file, index=False)\n",
        "\n",
        "# step 4: link notes with their code\n",
        "labeled = concat_data('%s/ALL_CODES_filtered.csv' % args.MIMIC_3_DIR, sorted_file, '%s/notes_labeled.csv' % args.MIMIC_3_DIR)\n",
        "\n",
        "dfnl = pd.read_csv(labeled)\n",
        "\n",
        "# step 5: statistic unique word, total word, HADM_ID number\n",
        "types = set()\n",
        "num_tok = 0\n",
        "for row in dfnl.itertuples():\n",
        "    for w in row[3].split():\n",
        "        types.add(w)\n",
        "        num_tok += 1\n",
        "\n",
        "print(\"num types\", len(types), \"num tokens\", num_tok)\n",
        "print(\"HADM_ID: {}\".format(len(dfnl['HADM_ID'].unique())))\n",
        "print(\"SUBJECT_ID: {}\".format(len(dfnl['SUBJECT_ID'].unique())))\n",
        "\n",
        "# step 6: split data into train dev test\n",
        "fname = '%s/notes_labeled.csv' % args.MIMIC_3_DIR\n",
        "base_name = \"%s/disch\" % args.MIMIC_3_DIR #for output\n",
        "tr, dv, te = split_data(fname, base_name, args.MIMIC_3_DIR)\n",
        "\n",
        "vocab_min = 3\n",
        "vname = '%s/vocab.csv' % args.MIMIC_3_DIR\n",
        "build_vocab(vocab_min, tr, vname, True)\n",
        "\n",
        "# build vocab for RAC model\n",
        "vocab_min = 3\n",
        "vname = '%s/vocab_rac.csv' % args.MIMIC_3_DIR\n",
        "build_vocab(vocab_min, tr, vname, True)\n",
        "\n",
        "# step 7: sort data by its note length, add length to the last column\n",
        "for splt in ['train', 'dev', 'test']:\n",
        "    filename = '%s/disch_%s_split.csv' % (args.MIMIC_3_DIR, splt)\n",
        "    df = pd.read_csv(filename)\n",
        "    df['length'] = df.apply(lambda row: len(str(row['TEXT']).split()), axis=1)\n",
        "    df = df.sort_values(['length'])\n",
        "    df.to_csv('%s/%s_full.csv' % (args.MIMIC_3_DIR, splt), index=False)\n",
        "\n",
        "# step 8: train word embeddings via word2vec and fasttext\n",
        "w2v_file = word_embeddings('full', '%s/disch_full.csv' % args.MIMIC_3_DIR, 100, 0, 5)\n",
        "gensim_to_embeddings('%s/processed_full_100.w2v' % args.MIMIC_3_DIR, '%s/vocab.csv' % args.MIMIC_3_DIR, Y)\n",
        "\n",
        "# fasttext_file = fasttext_embeddings('full', '%s/disch_full.csv' % args.MIMIC_3_DIR, 100, 0, 5)\n",
        "# gensim_to_fasttext_embeddings('%s/processed_full_100.fasttext' % args.MIMIC_3_DIR, '%s/vocab.csv' % args.MIMIC_3_DIR, Y)\n",
        "\n",
        "# generate word embeddings (300 dimensions) for convolved embedding model\n",
        "w2v_file = word_embeddings('full', '%s/disch_full.csv' % args.MIMIC_3_DIR, 300, 0, 5)\n",
        "gensim_to_embeddings('%s/processed_full_300.w2v' % args.MIMIC_3_DIR, '%s/vocab_rac.csv' % args.MIMIC_3_DIR, Y)\n",
        "\n",
        "# fasttext_file = fasttext_embeddings('full', '%s/disch_full.csv' % args.MIMIC_3_DIR, 300, 10, 5)\n",
        "# gensim_to_fasttext_embeddings('%s/processed_full_300.fasttext' % args.MIMIC_3_DIR, '%s/vocab_rac.csv' % args.MIMIC_3_DIR, Y)\n",
        "\n",
        "# step 9: statistic the top 50 code\n",
        "Y = 50\n",
        "\n",
        "counts = Counter()\n",
        "dfnl = pd.read_csv('%s/notes_labeled.csv' % args.MIMIC_3_DIR)\n",
        "for row in dfnl.itertuples():\n",
        "    for label in str(row[4]).split(';'):\n",
        "        counts[label] += 1\n",
        "\n",
        "codes_50 = sorted(counts.items(), key=operator.itemgetter(1), reverse=True)\n",
        "\n",
        "codes_50 = [code[0] for code in codes_50[:Y]]\n",
        "\n",
        "with open('%s/TOP_%s_CODES.csv' % (args.MIMIC_3_DIR, str(Y)), 'w', newline='') as of:\n",
        "    w = csv.writer(of)\n",
        "    for code in codes_50:\n",
        "        w.writerow([code])\n",
        "\n",
        "# step 10: split data according to train_50_hadm_ids dev... and test...\n",
        "for splt in ['train', 'dev', 'test']:\n",
        "    print(splt)\n",
        "    hadm_ids = set()\n",
        "    with open('%s/%s_50_hadm_ids.csv' % (args.MIMIC_3_DIR, splt), 'r') as f:\n",
        "        for line in f:\n",
        "            hadm_ids.add(line.rstrip())\n",
        "    with open('%s/notes_labeled.csv' % args.MIMIC_3_DIR, 'r') as f:\n",
        "        with open('%s/%s_%s.csv' % (args.MIMIC_3_DIR, splt, str(Y)), 'w', newline='') as of:\n",
        "            r = csv.reader(f)\n",
        "            w = csv.writer(of)\n",
        "            #header\n",
        "            w.writerow(next(r))\n",
        "            i = 0\n",
        "            for row in r:\n",
        "                hadm_id = row[1]\n",
        "                if hadm_id not in hadm_ids:\n",
        "                    continue\n",
        "                codes = set(str(row[3]).split(';'))\n",
        "                filtered_codes = codes.intersection(set(codes_50))\n",
        "                if len(filtered_codes) > 0:\n",
        "                    w.writerow(row[:3] + [';'.join(filtered_codes)])\n",
        "                    i += 1\n",
        "\n",
        "# step 11: sort data by its note length, add length to the last column\n",
        "for splt in ['train', 'dev', 'test']:\n",
        "    filename = '%s/%s_%s.csv' % (args.MIMIC_3_DIR, splt, str(Y))\n",
        "    df = pd.read_csv(filename)\n",
        "    df['length'] = df.apply(lambda row: len(str(row['TEXT']).split()), axis=1)\n",
        "    df = df.sort_values(['length'])\n",
        "    df.to_csv('%s/%s_%s.csv' % (args.MIMIC_3_DIR, splt, str(Y)), index=False)"
      ],
      "metadata": {
        "id": "Uy9DwIJPkifv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model\n",
        "### Model Overview\n",
        "The model defined in the code includes several classes representing different neural network architectures for automated ICD coding. These models include configurations for handling multi-label classification with a focus on curriculum learning and label hierarchies.\n",
        "\n",
        "### Model Architecture\n",
        "- **Word Representation (WordRep) Module:**\n",
        "  - **Embedding Layer:** Utilizes pretrained embeddings with a dimension depending on the pretrained file, or initializes a new embedding layer if no pretrained file is provided. The embedding size can be 100, 300, etc., based on the available data.\n",
        "  - **Dropout:** Applied after the embedding layer to prevent overfitting, with a dropout rate of 0.1 as configured in the model settings. This helps improve the model's generalization capability on unseen data.\n",
        "\n",
        "- **Decoders:**\n",
        "  - **RandomlyInitializedDecoder, RACDecoder, LAATDecoder, Decoder:** Each uses an attention mechanism tailored to the needs of hierarchical ICD code prediction.\n",
        "    - **Attention Units:** Typically involves layers with dimensions tuned to the size of the dataset labels (e.g., number of ICD codes).\n",
        "    - **Activation Function:** Uses Tanh or ReLU in intermediate layers to introduce non-linearity.\n",
        "    - **Hyperbolic Embedding Layers:** Specific to HiCuA strategies, embedding sizes match the hyperbolic space dimensions used (commonly around 50 dimensions).\n",
        "\n",
        "- **MultiResCNN:**\n",
        "  - **Convolutional Layers:** Multiple convolutional layers with filter sizes that may vary from small (3-5 words) to large (7-9 words) to capture different levels of textual granularity.\n",
        "  - **Residual Connections:** Helps in flowing gradients and avoiding the vanishing gradient problem in deep networks.\n",
        "  - **Activation Function:** Uses Tanh activation functions following convolutional layers to add non-linearity.\n",
        "\n",
        "- **LongformerClassifier:**\n",
        "  - **Longformer Layers:** Uses a Longformer architecture, suitable for processing long text sequences with attention mechanisms that focus on different parts of the input sequence efficiently.\n",
        "  - **Configuration:** Configured with parameters such as number of attention heads, hidden dimensions (typically 768 for base models), and specific attention window sizes.\n",
        "\n",
        "### Training Objectives\n",
        "- **Loss Functions:**\n",
        "  - **Binary Cross-Entropy Loss:** Used for binary classification tasks such as ICD code prediction from clinical texts.\n",
        "  - **Asymmetric Loss:** Customized to handle imbalanced datasets, focusing more on the minority classes which are crucial in medical code predictions.\n",
        "- **Optimizer:**\n",
        "  - **Adam Optimizer:** Widely used for its efficiency in handling sparse gradients and adaptive learning rate capabilities.\n",
        "\n",
        "### Additional Configuration\n",
        "- **Pretrained Models:** Uses pretrained Longformer or other transformer models fine-tuned on medical texts to leverage prior knowledge and improve prediction accuracy.\n",
        "- **Monte Carlo Simulation:** Not directly mentioned in the paper, but could be integrated for evaluating model robustness and uncertainty in predictions.\n",
        "\n",
        "### Implementation Details\n",
        "- **Classes and Methods:** Code structure involves defining Python classes for each model type (e.g., `MultiResCNN`, `LAAT`), with methods for each operation like `forward` pass, loss computation, and backpropagation.\n",
        "- **Model Validation and Testing:** Functions to evaluate model performance on a validation set during training and a separate test set to assess generalizability.\n",
        "raining and a separate test set to assess generalizability."
      ],
      "metadata": {
        "id": "3muyDPFPbozY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Pre-trained Model (MultiResCNN HiCuA)\n",
        "\n",
        "This code snippet is intended to load the checkpoint for the MultiResCNN with HiCuA architecture, primarily for validation and analysis within Google Colab. Please note that the code is currently not configured to function correctly within Google Colab, despite being able to load. However, adjustments are planned to ensure compatibility in the near future.\n",
        "\n",
        "**It is important to mention that other models, such as `RAC with HiCuA` and `LAAT with HiCuA + ASL`, are still undergoing training on dedicated hardware. Once the training for these models is completed, they will be incorporated into this notebook. As a result, this section is expected to expand and include the newly trained models, enhancing the functionality and scope of the code snippet.**"
      ],
      "metadata": {
        "id": "JuuruiiNkHtC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "class WordRep(nn.Module):\n",
        "    def __init__(self, embed_file, vocab_size, embed_dim, dropout):\n",
        "        super(WordRep, self).__init__()\n",
        "        if embed_file:\n",
        "            embeddings = np.load(embed_file)\n",
        "            W = torch.from_numpy(embeddings).float()\n",
        "        else:\n",
        "            W = torch.randn(vocab_size, embed_dim)\n",
        "        self.embed = nn.Embedding.from_pretrained(W, freeze=False)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.dropout(self.embed(x))\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, dropout):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.left = nn.Sequential(\n",
        "            nn.Conv1d(in_channels, out_channels, kernel_size=kernel_size, padding=kernel_size//2, bias=False),\n",
        "            nn.BatchNorm1d(out_channels),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(out_channels, out_channels, kernel_size=kernel_size, padding=kernel_size//2, bias=False),\n",
        "            nn.BatchNorm1d(out_channels)\n",
        "        )\n",
        "        self.shortcut = nn.Sequential(\n",
        "            nn.Conv1d(in_channels, out_channels, kernel_size=1, stride=1, bias=False),\n",
        "            nn.BatchNorm1d(out_channels)\n",
        "        )\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.left(x) + self.shortcut(x)\n",
        "        return self.dropout(out)\n",
        "\n",
        "class MultiResCNN(nn.Module):\n",
        "    def __init__(self, embed_file, vocab_size, embed_size, num_filters, kernel_sizes, dropout):\n",
        "        super(MultiResCNN, self).__init__()\n",
        "        self.word_rep = WordRep(embed_file, vocab_size, embed_size, dropout)\n",
        "        self.conv = nn.ModuleList()\n",
        "        for size in kernel_sizes:\n",
        "            self.conv.append(ResidualBlock(embed_size, num_filters, size, dropout))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.word_rep(x).transpose(1, 2)\n",
        "        for conv in self.conv:\n",
        "            x = conv(x)\n",
        "        return x\n",
        "\n",
        "def load_model(model_path, embed_file, vocab_size, embed_size, num_filters, kernel_sizes, dropout):\n",
        "    model = MultiResCNN(embed_file, vocab_size, embed_size, num_filters, kernel_sizes, dropout)\n",
        "    # model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "# Specify paths and parameters\n",
        "model_path = '/content/drive/My Drive/multirescnn_hicua.pth'\n",
        "embed_file = '/content/drive/My Drive/processed_full_100.w2v.wv.vectors.npy'\n",
        "vocab_size = 51921\n",
        "embed_size = 100\n",
        "num_filters = 50\n",
        "kernel_sizes = [3, 5, 9, 15, 19, 25]\n",
        "dropout = 0.2\n",
        "\n",
        "model = load_model(model_path, embed_file, vocab_size, embed_size, num_filters, kernel_sizes, dropout)\n",
        "print(model)"
      ],
      "metadata": {
        "id": "Q9P1b2hvWpaW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementation of Training Code\n",
        "\n",
        "**Currently the code is not optimized to run in Google Collab, and it doesn't need to as the training is done on a dedicated machine off of Colab, but I aim to address this in coming days.**"
      ],
      "metadata": {
        "id": "6-wIjaCDo0VM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.init import xavier_uniform_ as xavier_uniform\n",
        "import numpy as np\n",
        "from utils.utils import build_pretrain_embedding, load_embeddings\n",
        "from utils.losses import AsymmetricLoss, AsymmetricLossOptimized\n",
        "from math import floor, sqrt\n",
        "\n",
        "\n",
        "class WordRep(nn.Module):\n",
        "    def __init__(self, args, Y, dicts):\n",
        "        super(WordRep, self).__init__()\n",
        "\n",
        "        if args.embed_file:\n",
        "            print(\"loading pretrained embeddings from {}\".format(args.embed_file))\n",
        "            if args.use_ext_emb:\n",
        "                pretrain_word_embedding, pretrain_emb_dim = build_pretrain_embedding(args.embed_file, dicts['w2ind'],\n",
        "                                                                                     True)\n",
        "                W = torch.from_numpy(pretrain_word_embedding)\n",
        "            else:\n",
        "                W = torch.Tensor(load_embeddings(args.embed_file))\n",
        "\n",
        "            self.embed = nn.Embedding(W.size()[0], W.size()[1], padding_idx=0)\n",
        "            self.embed.weight.data = W.clone()\n",
        "        else:\n",
        "            # add 2 to include UNK and PAD\n",
        "            self.embed = nn.Embedding(len(dicts['w2ind']) + 2, args.embed_size, padding_idx=0)\n",
        "        self.feature_size = self.embed.embedding_dim\n",
        "\n",
        "        self.embed_drop = nn.Dropout(p=args.dropout)\n",
        "\n",
        "        self.conv_dict = {1: [self.feature_size, args.num_filter_maps],\n",
        "                     2: [self.feature_size, 100, args.num_filter_maps],\n",
        "                     3: [self.feature_size, 150, 100, args.num_filter_maps],\n",
        "                     4: [self.feature_size, 200, 150, 100, args.num_filter_maps]\n",
        "                     }\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = [self.embed(x)]\n",
        "\n",
        "        x = torch.cat(features, dim=2)\n",
        "\n",
        "        x = self.embed_drop(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class RandomlyInitializedDecoder(nn.Module):\n",
        "    \"\"\"\n",
        "    The original per-label attention network: query matrix is randomly initialized\n",
        "    \"\"\"\n",
        "    def __init__(self, args, Y, dicts, input_size):\n",
        "        super(RandomlyInitializedDecoder, self).__init__()\n",
        "\n",
        "        Y = Y[-1]\n",
        "\n",
        "        self.U = nn.Linear(input_size, Y)\n",
        "        xavier_uniform(self.U.weight)\n",
        "\n",
        "\n",
        "        self.final = nn.Linear(input_size, Y)\n",
        "        xavier_uniform(self.final.weight)\n",
        "\n",
        "        self.loss_function = nn.BCEWithLogitsLoss()\n",
        "\n",
        "\n",
        "    def forward(self, x, target, text_inputs):\n",
        "        # attention\n",
        "        alpha = F.softmax(self.U.weight.matmul(x.transpose(1, 2)), dim=2)\n",
        "\n",
        "        m = alpha.matmul(x)\n",
        "\n",
        "        y = self.final.weight.mul(m).sum(dim=2).add(self.final.bias)\n",
        "\n",
        "        loss = self.loss_function(y, target)\n",
        "        return y, loss, alpha, m\n",
        "\n",
        "    def change_depth(self, depth=0):\n",
        "        # placeholder\n",
        "        pass\n",
        "\n",
        "\n",
        "class RACDecoder(nn.Module):\n",
        "    \"\"\"\n",
        "    The decoder proposed by Kim et al. (Code title-guided attention)\n",
        "    \"\"\"\n",
        "    def __init__(self, args, Y, dicts, input_size):\n",
        "        super(RACDecoder, self).__init__()\n",
        "\n",
        "        Y = Y[-1]\n",
        "\n",
        "        self.input_size = input_size\n",
        "\n",
        "        self.register_buffer(\"c2title\", torch.LongTensor(dicts[\"c2title\"]))\n",
        "        self.word_rep = WordRep(args, Y, dicts)\n",
        "\n",
        "        filter_size = int(args.code_title_filter_size)\n",
        "        self.code_title_conv = nn.Conv1d(self.word_rep.feature_size, input_size,\n",
        "                                         filter_size, padding=int(floor(filter_size / 2)))\n",
        "        xavier_uniform(self.code_title_conv.weight)\n",
        "        self.code_title_maxpool = nn.MaxPool1d(args.num_code_title_tokens)\n",
        "\n",
        "        self.final = nn.Linear(input_size, Y)\n",
        "        xavier_uniform(self.final.weight)\n",
        "\n",
        "        self.loss_function = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    def forward(self, x, target, text_inputs):\n",
        "        code_title = self.word_rep(self._buffers['c2title']).transpose(1, 2)\n",
        "        # attention\n",
        "        U = self.code_title_conv(code_title)\n",
        "        U = self.code_title_maxpool(U).squeeze(-1)\n",
        "        U = torch.tanh(U)\n",
        "\n",
        "        attention_score = U.matmul(x.transpose(1, 2)) / sqrt(self.input_size)\n",
        "        alpha = F.softmax(attention_score, dim=2)\n",
        "\n",
        "        m = alpha.matmul(x)\n",
        "\n",
        "        y = self.final.weight.mul(m).sum(dim=2).add(self.final.bias)\n",
        "\n",
        "        loss = self.loss_function(y, target)\n",
        "        return y, loss, alpha, m\n",
        "\n",
        "    def change_depth(self, depth=0):\n",
        "        # placeholder\n",
        "        pass\n",
        "\n",
        "\n",
        "class LAATDecoder(nn.Module):\n",
        "    def __init__(self, args, Y, dicts, input_size):\n",
        "        super(LAATDecoder, self).__init__()\n",
        "\n",
        "        Y = Y[-1]\n",
        "\n",
        "        self.attn_dim = args.attn_dim\n",
        "        self.W = nn.Linear(input_size, self.attn_dim)\n",
        "        self.U = nn.Linear(self.attn_dim, Y)\n",
        "        xavier_uniform(self.W.weight)\n",
        "        xavier_uniform(self.U.weight)\n",
        "\n",
        "        self.final = nn.Linear(input_size, Y)\n",
        "        xavier_uniform(self.final.weight)\n",
        "\n",
        "        self.loss_function = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    def forward(self, x, target, text_inputs):\n",
        "        z = torch.tanh(self.W(x))\n",
        "        # attention\n",
        "        alpha = F.softmax(self.U.weight.matmul(z.transpose(1, 2)), dim=2)\n",
        "\n",
        "        m = alpha.matmul(x)\n",
        "\n",
        "        y = self.final.weight.mul(m).sum(dim=2).add(self.final.bias)\n",
        "\n",
        "        loss = self.loss_function(y, target)\n",
        "        return y, loss, alpha, m\n",
        "\n",
        "    def change_depth(self, depth=0):\n",
        "        # placeholder\n",
        "        pass\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    \"\"\"\n",
        "    Decoder: knowledge transfer initialization and hyperbolic embedding correction\n",
        "    \"\"\"\n",
        "    def __init__(self, args, Y, dicts, input_size):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.dicts = dicts\n",
        "\n",
        "        self.decoder_dict = nn.ModuleDict()\n",
        "        for i in range(len(Y)):\n",
        "            y = Y[i]\n",
        "            self.decoder_dict[str(i) + '_' + '0'] = nn.Linear(input_size, y)\n",
        "            self.decoder_dict[str(i) + '_' + '1'] = nn.Linear(input_size, y)\n",
        "            xavier_uniform(self.decoder_dict[str(i) + '_' + '0'].weight)\n",
        "            xavier_uniform(self.decoder_dict[str(i) + '_' + '1'].weight)\n",
        "\n",
        "        self.use_hyperbolic =  args.decoder.find(\"Hyperbolic\") != -1\n",
        "        if self.use_hyperbolic:\n",
        "            self.cat_hyperbolic = args.cat_hyperbolic\n",
        "            if not self.cat_hyperbolic:\n",
        "                self.hyperbolic_fc_dict = nn.ModuleDict()\n",
        "                for i in range(len(Y)):\n",
        "                    self.hyperbolic_fc_dict[str(i)] = nn.Linear(args.hyperbolic_dim, input_size)\n",
        "            else:\n",
        "                self.query_fc_dict = nn.ModuleDict()\n",
        "                for i in range(len(Y)):\n",
        "                    self.query_fc_dict[str(i)] = nn.Linear(input_size + args.hyperbolic_dim, input_size)\n",
        "\n",
        "            # build hyperbolic embedding matrix\n",
        "            self.hyperbolic_emb_dict = {}\n",
        "            for i in range(len(Y)):\n",
        "                self.hyperbolic_emb_dict[i] = np.zeros((Y[i], args.hyperbolic_dim))\n",
        "                for idx, code in dicts['ind2c'][i].items():\n",
        "                    self.hyperbolic_emb_dict[i][idx, :] = np.copy(dicts['poincare_embeddings'].get_vector(code))\n",
        "                self.register_buffer(name='hb_emb_' + str(i), tensor=torch.tensor(self.hyperbolic_emb_dict[i], dtype=torch.float32))\n",
        "\n",
        "        self.cur_depth = 5 - args.depth\n",
        "        self.is_init = False\n",
        "        self.change_depth(self.cur_depth)\n",
        "\n",
        "        if args.loss == 'BCE':\n",
        "            self.loss_function = nn.BCEWithLogitsLoss()\n",
        "        elif args.loss == 'ASL':\n",
        "            asl_config = [float(c) for c in args.asl_config.split(',')]\n",
        "            self.loss_function = AsymmetricLoss(gamma_neg=asl_config[0], gamma_pos=asl_config[1],\n",
        "                                                clip=asl_config[2], reduction=args.asl_reduction)\n",
        "        elif args.loss == 'ASLO':\n",
        "            asl_config = [float(c) for c in args.asl_config.split(',')]\n",
        "            self.loss_function = AsymmetricLossOptimized(gamma_neg=asl_config[0], gamma_pos=asl_config[1],\n",
        "                                                         clip=asl_config[2], reduction=args.asl_reduction)\n",
        "\n",
        "    def change_depth(self, depth=0):\n",
        "        if self.is_init:\n",
        "            # copy previous attention weights to current attention network based on ICD hierarchy\n",
        "            ind2c = self.dicts['ind2c']\n",
        "            c2ind = self.dicts['c2ind']\n",
        "            hierarchy_dist = self.dicts['hierarchy_dist']\n",
        "            for i, code in ind2c[depth].items():\n",
        "                tree = hierarchy_dist[depth][code]\n",
        "                pre_idx = c2ind[depth - 1][tree[depth - 1]]\n",
        "\n",
        "                self.decoder_dict[str(depth) + '_' + '0'].weight.data[i, :] = self.decoder_dict[str(depth - 1) + '_' + '0'].weight.data[pre_idx, :].clone()\n",
        "                self.decoder_dict[str(depth) + '_' + '1'].weight.data[i, :] = self.decoder_dict[str(depth - 1) + '_' + '1'].weight.data[pre_idx, :].clone()\n",
        "\n",
        "        if not self.is_init:\n",
        "            self.is_init = True\n",
        "\n",
        "        self.cur_depth = depth\n",
        "\n",
        "    def forward(self, x, target, text_inputs):\n",
        "        # attention\n",
        "        if self.use_hyperbolic:\n",
        "            if not self.cat_hyperbolic:\n",
        "                query = self.decoder_dict[str(self.cur_depth) + '_' + '0'].weight + self.hyperbolic_fc_dict[str(self.cur_depth)](self._buffers['hb_emb_' + str(self.cur_depth)])\n",
        "            else:\n",
        "                query = torch.cat([self.decoder_dict[str(self.cur_depth) + '_' + '0'].weight, self._buffers['hb_emb_' + str(self.cur_depth)]], dim=1)\n",
        "                query = self.query_fc_dict[str(self.cur_depth)](query)\n",
        "        else:\n",
        "            query = self.decoder_dict[str(self.cur_depth) + '_' + '0'].weight\n",
        "\n",
        "        alpha = F.softmax(query.matmul(x.transpose(1, 2)), dim=2)\n",
        "        m = alpha.matmul(x)\n",
        "\n",
        "        y = self.decoder_dict[str(self.cur_depth) + '_' + '1'].weight.mul(m).sum(dim=2).add(self.decoder_dict[str(self.cur_depth) + '_' + '1'].bias)\n",
        "\n",
        "        loss = self.loss_function(y, target)\n",
        "\n",
        "        return y, loss, alpha, m\n",
        "\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, inchannel, outchannel, kernel_size, stride, use_res, dropout):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.left = nn.Sequential(\n",
        "            nn.Conv1d(inchannel, outchannel, kernel_size=kernel_size, stride=stride, padding=int(floor(kernel_size / 2)), bias=False),\n",
        "            nn.BatchNorm1d(outchannel),\n",
        "            nn.Tanh(),\n",
        "            nn.Conv1d(outchannel, outchannel, kernel_size=kernel_size, stride=1, padding=int(floor(kernel_size / 2)), bias=False),\n",
        "            nn.BatchNorm1d(outchannel)\n",
        "        )\n",
        "\n",
        "        self.use_res = use_res\n",
        "        if self.use_res:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                        nn.Conv1d(inchannel, outchannel, kernel_size=1, stride=stride, bias=False),\n",
        "                        nn.BatchNorm1d(outchannel)\n",
        "                    )\n",
        "\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.left(x)\n",
        "        if self.use_res:\n",
        "            out += self.shortcut(x)\n",
        "        out = torch.tanh(out)\n",
        "        out = self.dropout(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class MultiResCNN(nn.Module):\n",
        "\n",
        "    def __init__(self, args, Y, dicts):\n",
        "        super(MultiResCNN, self).__init__()\n",
        "\n",
        "        self.word_rep = WordRep(args, Y, dicts)\n",
        "\n",
        "        self.conv = nn.ModuleList()\n",
        "        filter_sizes = args.filter_size.split(',')\n",
        "\n",
        "        self.filter_num = len(filter_sizes)\n",
        "        for filter_size in filter_sizes:\n",
        "            filter_size = int(filter_size)\n",
        "            one_channel = nn.ModuleList()\n",
        "            tmp = nn.Conv1d(self.word_rep.feature_size, self.word_rep.feature_size, kernel_size=filter_size,\n",
        "                            padding=int(floor(filter_size / 2)))\n",
        "            xavier_uniform(tmp.weight)\n",
        "            one_channel.add_module('baseconv', tmp)\n",
        "\n",
        "            conv_dimension = self.word_rep.conv_dict[args.conv_layer]\n",
        "            for idx in range(args.conv_layer):\n",
        "                tmp = ResidualBlock(conv_dimension[idx], conv_dimension[idx + 1], filter_size, 1, True,\n",
        "                                    args.dropout)\n",
        "                one_channel.add_module('resconv-{}'.format(idx), tmp)\n",
        "\n",
        "            self.conv.add_module('channel-{}'.format(filter_size), one_channel)\n",
        "\n",
        "        if args.decoder == \"HierarchicalHyperbolic\" or args.decoder == \"Hierarchical\":\n",
        "            self.decoder = Decoder(args, Y, dicts, self.filter_num * args.num_filter_maps)\n",
        "        elif args.decoder == \"RandomlyInitialized\":\n",
        "            self.decoder = RandomlyInitializedDecoder(args, Y, dicts, self.filter_num * args.num_filter_maps)\n",
        "        elif args.decoder == \"CodeTitle\":\n",
        "            self.decoder = RACDecoder(args, Y, dicts, self.filter_num * args.num_filter_maps)\n",
        "        else:\n",
        "            raise RuntimeError(\"wrong decoder name\")\n",
        "\n",
        "        self.cur_depth = 5 - args.depth\n",
        "\n",
        "\n",
        "    def forward(self, x, target, text_inputs):\n",
        "        x = self.word_rep(x)\n",
        "\n",
        "        x = x.transpose(1, 2)\n",
        "\n",
        "        conv_result = []\n",
        "        for conv in self.conv:\n",
        "            tmp = x\n",
        "            for idx, md in enumerate(conv):\n",
        "                if idx == 0:\n",
        "                    tmp = torch.tanh(md(tmp))\n",
        "                else:\n",
        "                    tmp = md(tmp)\n",
        "            tmp = tmp.transpose(1, 2)\n",
        "            conv_result.append(tmp)\n",
        "        x = torch.cat(conv_result, dim=2)\n",
        "\n",
        "        y, loss, alpha, m = self.decoder(x, target, text_inputs)\n",
        "\n",
        "        return y, loss, alpha, m\n",
        "\n",
        "    def freeze_net(self):\n",
        "        for p in self.word_rep.embed.parameters():\n",
        "            p.requires_grad = False\n",
        "\n",
        "import os\n",
        "from transformers import LongformerModel, LongformerConfig\n",
        "class LongformerClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self, args, Y, dicts):\n",
        "        super(LongformerClassifier, self).__init__()\n",
        "\n",
        "        if args.longformer_dir != '':\n",
        "            print(\"loading pretrained longformer from {}\".format(args.longformer_dir))\n",
        "            config_file = os.path.join(args.longformer_dir, 'config.json')\n",
        "            self.config = LongformerConfig.from_json_file(config_file)\n",
        "            print(\"Model config {}\".format(self.config))\n",
        "            self.longformer = LongformerModel.from_pretrained(args.longformer_dir, gradient_checkpointing=True)\n",
        "        else:\n",
        "            self.config = LongformerConfig(\n",
        "                attention_mode=\"longformer\",\n",
        "                attention_probs_dropout_prob=0.1,\n",
        "                attention_window=[\n",
        "                    512,\n",
        "                    512,\n",
        "                    512,\n",
        "                    512,\n",
        "                    512,\n",
        "                    512,\n",
        "                ],\n",
        "                bos_token_id=0,\n",
        "                eos_token_id=2,\n",
        "                gradient_checkpointing=False,\n",
        "                hidden_act=\"gelu\",\n",
        "                hidden_dropout_prob=0.1,\n",
        "                hidden_size=768,\n",
        "                ignore_attention_mask=False,\n",
        "                initializer_range=0.02,\n",
        "                intermediate_size=3072,\n",
        "                layer_norm_eps=1e-05,\n",
        "                max_position_embeddings=4098,\n",
        "                model_type=\"longformer\",\n",
        "                num_attention_heads=12,\n",
        "                num_hidden_layers=6,\n",
        "                pad_token_id=1,\n",
        "                sep_token_id=2,\n",
        "                type_vocab_size=1,\n",
        "                vocab_size=50265\n",
        "            )\n",
        "            self.longformer = LongformerModel(self.config)\n",
        "\n",
        "        # decoder\n",
        "        self.decoder = Decoder(args, Y, dicts, self.config.hidden_size)\n",
        "\n",
        "\n",
        "    def forward(self, input_ids, token_type_ids, attention_mask, target):\n",
        "        global_attention_mask = torch.zeros_like(input_ids)\n",
        "            # global attention on cls token\n",
        "            # global_attention_mask[:, 0] = 1 # this line should be commented if using decoder\n",
        "        longformer_output = self.longformer(\n",
        "            input_ids=input_ids,\n",
        "            token_type_ids=token_type_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            global_attention_mask=global_attention_mask,\n",
        "            return_dict=False\n",
        "        )\n",
        "\n",
        "        output = longformer_output[0]\n",
        "        y, loss, alpha, m = self.decoder(output, target, None)\n",
        "\n",
        "        return y, loss, alpha, m\n",
        "\n",
        "    def freeze_net(self):\n",
        "        pass\n",
        "\n",
        "\n",
        "class RACReader(nn.Module):\n",
        "    def __init__(self, args, Y, dicts):\n",
        "        super(RACReader, self).__init__()\n",
        "\n",
        "        self.word_rep = WordRep(args, Y, dicts)\n",
        "        filter_size = int(args.filter_size)\n",
        "\n",
        "        self.conv = nn.ModuleList()\n",
        "        for i in range(args.reader_conv_num):\n",
        "            conv = nn.Conv1d(self.word_rep.feature_size, self.word_rep.feature_size, kernel_size=filter_size,\n",
        "                                padding=int(floor(filter_size / 2)))\n",
        "            xavier_uniform(conv.weight)\n",
        "            self.conv.add_module(f'conv_{i+1}', conv)\n",
        "\n",
        "        self.dropout = nn.Dropout(p=args.dropout)\n",
        "\n",
        "        self.trans = nn.ModuleList()\n",
        "        for i in range(args.reader_trans_num):\n",
        "            trans = nn.TransformerEncoderLayer(self.word_rep.feature_size, 1, args.trans_ff_dim, args.dropout, \"relu\")\n",
        "            self.trans.add_module(f'trans_{i+1}', trans)\n",
        "\n",
        "        if args.decoder == \"HierarchicalHyperbolic\" or args.decoder == \"Hierarchical\":\n",
        "            self.decoder = Decoder(args, Y, dicts, self.word_rep.feature_size)\n",
        "        elif args.decoder == \"RandomlyInitialized\":\n",
        "            self.decoder = RandomlyInitializedDecoder(args, Y, dicts, self.word_rep.feature_size)\n",
        "        elif args.decoder == \"CodeTitle\":\n",
        "            self.decoder = RACDecoder(args, Y, dicts, self.word_rep.feature_size)\n",
        "        else:\n",
        "            raise RuntimeError(\"wrong decoder name\")\n",
        "\n",
        "    def forward(self, x, target, text_inputs=None):\n",
        "        x = self.word_rep(x)\n",
        "\n",
        "        x = x.transpose(1, 2)\n",
        "\n",
        "        for conv in self.conv:\n",
        "            x = conv(x)\n",
        "\n",
        "        x = torch.tanh(x).permute(2, 0, 1)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        for trans in self.trans:\n",
        "            x = trans(x)\n",
        "\n",
        "        x = x.permute(1, 0, 2)\n",
        "\n",
        "        y, loss, alpha, m = self.decoder(x, target, text_inputs)\n",
        "\n",
        "        return y, loss, alpha, m\n",
        "\n",
        "    def freeze_net(self):\n",
        "        for p in self.word_rep.embed.parameters():\n",
        "            p.requires_grad = False\n",
        "\n",
        "\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "class LAAT(nn.Module):\n",
        "    def __init__(self, args, Y, dicts):\n",
        "        super(LAAT, self).__init__()\n",
        "        self.word_rep = WordRep(args, Y, dicts)\n",
        "\n",
        "        self.hidden_dim = args.lstm_hidden_dim\n",
        "        self.biLSTM = nn.LSTM(\n",
        "            input_size=self.word_rep.feature_size,\n",
        "            hidden_size=self.hidden_dim,\n",
        "            batch_first=True,\n",
        "            dropout=args.dropout,\n",
        "            bidirectional=True\n",
        "        )\n",
        "\n",
        "        self.output_dim = 2 * self.hidden_dim\n",
        "        self.use_LAAT = False\n",
        "\n",
        "        self.attn_dim = args.attn_dim\n",
        "        self.decoder_name = args.decoder\n",
        "        if \"LAAT\" in args.decoder:\n",
        "            if args.decoder == \"LAATHierarchicalHyperbolic\" or args.decoder == \"LAATHierarchical\":\n",
        "                self.decoder_name = args.decoder[4:]\n",
        "            self.output_dim = self.attn_dim\n",
        "            self.use_LAAT = True\n",
        "            self.W = nn.Linear(2 * self.hidden_dim, self.attn_dim)\n",
        "\n",
        "        if self.decoder_name == \"HierarchicalHyperbolic\" or self.decoder_name == \"Hierarchical\":\n",
        "            self.decoder = Decoder(args, Y, dicts, self.output_dim)\n",
        "        elif self.decoder_name == \"RandomlyInitialized\":\n",
        "            self.decoder = RandomlyInitializedDecoder(args, Y, dicts, self.output_dim)\n",
        "        elif self.decoder_name == \"CodeTitle\":\n",
        "            self.decoder = RACDecoder(args, Y, dicts, self.output_dim)\n",
        "        elif self.decoder_name == \"LAATDecoder\":\n",
        "            self.decoder = RandomlyInitializedDecoder(args, Y, dicts, self.output_dim)\n",
        "        else:\n",
        "            raise RuntimeError(\"wrong decoder name\")\n",
        "\n",
        "\n",
        "\n",
        "        self.cur_depth = 5 - args.depth\n",
        "\n",
        "    def forward(self, x, target, text_inputs):\n",
        "        # lengths = (x > 0).sum(dim=1).cpu()\n",
        "        x = self.word_rep(x)  # [batch, length, input_size]\n",
        "\n",
        "        # x = pack_padded_sequence(x, lengths, batch_first=True, enforce_sorted=False)\n",
        "        x1 = self.biLSTM(x)[0]\n",
        "        # x1 = pad_packed_sequence(x1, batch_first=True)[0]\n",
        "\n",
        "        if self.use_LAAT:\n",
        "            x1 = torch.tanh(self.W(x1))\n",
        "\n",
        "        y, loss, alpha, m = self.decoder(x1, target, text_inputs)\n",
        "\n",
        "        return y, loss, alpha, m\n",
        "\n",
        "\n",
        "def pick_model(args, dicts):\n",
        "    ind2c = dicts['ind2c']\n",
        "    Y = [len(ind2c[i]) for i in range(5)] # total number of ICD codes\n",
        "    if args.model == 'MultiResCNN':\n",
        "        model = MultiResCNN(args, Y, dicts)\n",
        "    elif args.model == 'longformer':\n",
        "        model = LongformerClassifier(args, Y, dicts)\n",
        "    elif args.model == 'RACReader':\n",
        "        model = RACReader(args, Y, dicts)\n",
        "    elif args.model == 'LAAT':\n",
        "        model = LAAT(args, Y, dicts)\n",
        "    else:\n",
        "        raise RuntimeError(\"wrong model name\")\n",
        "\n",
        "    if args.test_model:\n",
        "        model.decoder.change_depth(4)\n",
        "        sd = torch.load(args.test_model)\n",
        "        model.load_state_dict(sd)\n",
        "    if args.tune_wordemb == False:\n",
        "        model.freeze_net()\n",
        "    if len(args.gpu_list) == 1 and args.gpu_list[0] != -1: # single card training\n",
        "        model.cuda()\n",
        "    elif len(args.gpu_list) > 1: # multi-card training\n",
        "        model = nn.DataParallel(model, device_ids=args.gpu_list)\n",
        "        model = model.to(f'cuda:{model.device_ids[0]}')\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "H_25Lyl0pgIe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training\n",
        "\n",
        "## Computational Requirements\n",
        "\n",
        "- **Bi-LSTM and MultiResCNN Models**: These models were trained on a single NVIDIA Tesla V100 GPU as stated in the paper.\n",
        "- **RAC Reader-based Models**: These required more computational power, utilizing 4 NVIDIA Tesla V100 GPUs for training.\n",
        "- **Current Setup**: I am using a single RTX 4090 GPU for training. The MultiResCNN with HiCuA has been successfully trained, while the RAC-based model with HiCuA is still undergoing training.\n",
        "\n",
        "## Implementation Code\n",
        "\n",
        "Due to the extent of the files included, I will provide the link to the GitHub repository at the following link, which contains the fork of the original HiCu-ICD project: [HiCu-ICD-UIUC-Evaluation](https://github.com/SaadatUIUC/HiCu-ICD-UIUC-Evaluation).\n",
        "\n",
        "**GitHub Address**: https://github.com/SaadatUIUC/HiCu-ICD-UIUC-Evaluation"
      ],
      "metadata": {
        "id": "OOlY2lk1opuf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Log for MultiResCNN with HiCuA\n",
        "\n",
        "The following section contains the log that was procued during the training of MutiResCNN with HiCuA on a dedicated machine.\n",
        "\n",
        "```\n",
        "(hicu_env) C:\\Users\\test\\UIUC\\HiCu-ICD-UIUC-Evaluation-Private>runs\\run_multirescnn_hicua.bat\n",
        "Namespace(DATA_DIR='./data', MAX_LENGTH=4096, MIMIC_2_DIR='./data/mimic2', MIMIC_3_DIR='./data/mimic3', MODEL_DIR='./models', Y='full', asl_config='0,0,0', asl_reduction='sum', attn_dim=512, batch_size=8, cat_hyperbolic=False, code_title_filter_size=9, command='python main.py --MODEL_DIR ./models --DATA_DIR ./data --MIMIC_3_DIR ./data/mimic3 --data_path ./data/mimic3/train_full.csv --embed_file ./data/mimic3/processed_full_100.embed --vocab ./data/mimic3/vocab.csv --Y full --model MultiResCNN --decoder HierarchicalHyperbolic --criterion prec_at_8 --MAX_LENGTH 4096 --batch_size 8 --lr 5e-5 --depth 5 --n_epochs 2,3,5,10,500 --num_workers 8 --hyperbolic_dim 50', conv_layer=1, criterion='prec_at_8', data_path='./data/mimic3/train_full.csv', decoder='HierarchicalHyperbolic', depth=5, dropout=0.2, embed_file='./data/mimic3/processed_full_100.embed', filter_size='3,5,9,15,19,25', gpu='0', gpu_list=[0], hyperbolic_dim=50, longformer_dir='', loss='BCE', lr=5e-05, lstm_hidden_dim=512, model='MultiResCNN', n_epochs='2,3,5,10,500', num_code_title_tokens=36, num_filter_maps=50, num_workers=8, patience=10, random_seed=1, reader_conv_num=2, reader_trans_num=4, scheduler=0.9, scheduler_patience=5, test_model=None, thres=0.5, trans_ff_dim=1024, tune_wordemb=True, use_ext_emb=False, version='mimic3', vocab='./data/mimic3/vocab.csv', weight_decay=0)\n",
        "loading lookups...\n",
        "Depth 0: 34\n",
        "Depth 1: 270\n",
        "Depth 2: 1158\n",
        "Depth 3: 5137\n",
        "Depth 4: 8921\n",
        "Training hyperbolic embeddings...\n",
        "loading pretrained embeddings from ./data/mimic3/processed_full_100.embed\n",
        "adding unk embedding\n",
        "MultiResCNN(\n",
        "  (word_rep): WordRep(\n",
        "    (embed): Embedding(51921, 100, padding_idx=0)\n",
        "    (embed_drop): Dropout(p=0.2, inplace=False)\n",
        "  )\n",
        "  (conv): ModuleList(\n",
        "    (channel-3): ModuleList(\n",
        "      (baseconv): Conv1d(100, 100, kernel_size=(3,), stride=(1,), padding=(1,))\n",
        "      (resconv-0): ResidualBlock(\n",
        "        (left): Sequential(\n",
        "          (0): Conv1d(100, 50, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
        "          (1): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "          (2): Tanh()\n",
        "          (3): Conv1d(50, 50, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
        "          (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        )\n",
        "        (shortcut): Sequential(\n",
        "          (0): Conv1d(100, 50, kernel_size=(1,), stride=(1,), bias=False)\n",
        "          (1): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        )\n",
        "        (dropout): Dropout(p=0.2, inplace=False)\n",
        "      )\n",
        "    )\n",
        "    (channel-5): ModuleList(\n",
        "      (baseconv): Conv1d(100, 100, kernel_size=(5,), stride=(1,), padding=(2,))\n",
        "      (resconv-0): ResidualBlock(\n",
        "        (left): Sequential(\n",
        "          (0): Conv1d(100, 50, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
        "          (1): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "          (2): Tanh()\n",
        "          (3): Conv1d(50, 50, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
        "          (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        )\n",
        "        (shortcut): Sequential(\n",
        "          (0): Conv1d(100, 50, kernel_size=(1,), stride=(1,), bias=False)\n",
        "          (1): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        )\n",
        "        (dropout): Dropout(p=0.2, inplace=False)\n",
        "      )\n",
        "    )\n",
        "    (channel-9): ModuleList(\n",
        "      (baseconv): Conv1d(100, 100, kernel_size=(9,), stride=(1,), padding=(4,))\n",
        "      (resconv-0): ResidualBlock(\n",
        "        (left): Sequential(\n",
        "          (0): Conv1d(100, 50, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
        "          (1): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "          (2): Tanh()\n",
        "          (3): Conv1d(50, 50, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
        "          (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        )\n",
        "        (shortcut): Sequential(\n",
        "          (0): Conv1d(100, 50, kernel_size=(1,), stride=(1,), bias=False)\n",
        "          (1): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        )\n",
        "        (dropout): Dropout(p=0.2, inplace=False)\n",
        "      )\n",
        "    )\n",
        "    (channel-15): ModuleList(\n",
        "      (baseconv): Conv1d(100, 100, kernel_size=(15,), stride=(1,), padding=(7,))\n",
        "      (resconv-0): ResidualBlock(\n",
        "        (left): Sequential(\n",
        "          (0): Conv1d(100, 50, kernel_size=(15,), stride=(1,), padding=(7,), bias=False)\n",
        "          (1): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "          (2): Tanh()\n",
        "          (3): Conv1d(50, 50, kernel_size=(15,), stride=(1,), padding=(7,), bias=False)\n",
        "          (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        )\n",
        "        (shortcut): Sequential(\n",
        "          (0): Conv1d(100, 50, kernel_size=(1,), stride=(1,), bias=False)\n",
        "          (1): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        )\n",
        "        (dropout): Dropout(p=0.2, inplace=False)\n",
        "      )\n",
        "    )\n",
        "    (channel-19): ModuleList(\n",
        "      (baseconv): Conv1d(100, 100, kernel_size=(19,), stride=(1,), padding=(9,))\n",
        "      (resconv-0): ResidualBlock(\n",
        "        (left): Sequential(\n",
        "          (0): Conv1d(100, 50, kernel_size=(19,), stride=(1,), padding=(9,), bias=False)\n",
        "          (1): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "          (2): Tanh()\n",
        "          (3): Conv1d(50, 50, kernel_size=(19,), stride=(1,), padding=(9,), bias=False)\n",
        "          (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        )\n",
        "        (shortcut): Sequential(\n",
        "          (0): Conv1d(100, 50, kernel_size=(1,), stride=(1,), bias=False)\n",
        "          (1): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        )\n",
        "        (dropout): Dropout(p=0.2, inplace=False)\n",
        "      )\n",
        "    )\n",
        "    (channel-25): ModuleList(\n",
        "      (baseconv): Conv1d(100, 100, kernel_size=(25,), stride=(1,), padding=(12,))\n",
        "      (resconv-0): ResidualBlock(\n",
        "        (left): Sequential(\n",
        "          (0): Conv1d(100, 50, kernel_size=(25,), stride=(1,), padding=(12,), bias=False)\n",
        "          (1): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "          (2): Tanh()\n",
        "          (3): Conv1d(50, 50, kernel_size=(25,), stride=(1,), padding=(12,), bias=False)\n",
        "          (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        )\n",
        "        (shortcut): Sequential(\n",
        "          (0): Conv1d(100, 50, kernel_size=(1,), stride=(1,), bias=False)\n",
        "          (1): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        )\n",
        "        (dropout): Dropout(p=0.2, inplace=False)\n",
        "      )\n",
        "    )\n",
        "  )\n",
        "  (decoder): Decoder(\n",
        "    (decoder_dict): ModuleDict(\n",
        "      (0_0): Linear(in_features=300, out_features=34, bias=True)\n",
        "      (0_1): Linear(in_features=300, out_features=34, bias=True)\n",
        "      (1_0): Linear(in_features=300, out_features=270, bias=True)\n",
        "      (1_1): Linear(in_features=300, out_features=270, bias=True)\n",
        "      (2_0): Linear(in_features=300, out_features=1158, bias=True)\n",
        "      (2_1): Linear(in_features=300, out_features=1158, bias=True)\n",
        "      (3_0): Linear(in_features=300, out_features=5137, bias=True)\n",
        "      (3_1): Linear(in_features=300, out_features=5137, bias=True)\n",
        "      (4_0): Linear(in_features=300, out_features=8921, bias=True)\n",
        "      (4_1): Linear(in_features=300, out_features=8921, bias=True)\n",
        "    )\n",
        "    (hyperbolic_fc_dict): ModuleDict(\n",
        "      (0): Linear(in_features=50, out_features=300, bias=True)\n",
        "      (1): Linear(in_features=50, out_features=300, bias=True)\n",
        "      (2): Linear(in_features=50, out_features=300, bias=True)\n",
        "      (3): Linear(in_features=50, out_features=300, bias=True)\n",
        "      (4): Linear(in_features=50, out_features=300, bias=True)\n",
        "    )\n",
        "    (loss_function): BCEWithLogitsLoss()\n",
        "  )\n",
        ")\n",
        "train_instances 47719\n",
        "dev_instances 1631\n",
        "test_instances 3372\n",
        "Total epochs at each level: [2, 3, 5, 10, 500]\n",
        "Training model at depth 0:\n",
        "EPOCH 0\n",
        "C:\\Users\\saada\\Desktop\\UIUC\\HiCu-ICD-UIUC-Evaluation-Private\\utils\\train_test.py:31: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:204.)\n",
        "  inputs_id, labels = torch.LongTensor(inputs_id), torch.FloatTensor(labels[cur_depth])\n",
        "epoch finish in 507.97s, loss: 0.3020\n",
        "file for evaluation: ./data/mimic3/dev_full.csv\n",
        "\n",
        "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.4229, 0.6272, 0.4867, 0.5481, 0.8636\n",
        "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.6121, 0.8197, 0.7073, 0.7594, 0.9414\n",
        "rec_at_5: 0.5307\n",
        "prec_at_5: 0.8748\n",
        "rec_at_8: 0.7171\n",
        "prec_at_8: 0.7665\n",
        "rec_at_15: 0.9379\n",
        "prec_at_15: 0.5623\n",
        "\n",
        "evaluation finish in 45.28s\n",
        "saved metrics, params, model to directory ./models\\MultiResCNN_HierarchicalHyperbolic_Apr_11_01_53_58\n",
        "\n",
        "EPOCH 1\n",
        "epoch finish in 527.53s, loss: 0.2510\n",
        "last epoch: testing on dev and test sets\n",
        "file for evaluation: ./data/mimic3/dev_full.csv\n",
        "\n",
        "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.4776, 0.6324, 0.5555, 0.5914, 0.8921\n",
        "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.6460, 0.8284, 0.7459, 0.7850, 0.9507\n",
        "rec_at_5: 0.5437\n",
        "prec_at_5: 0.8925\n",
        "rec_at_8: 0.7352\n",
        "prec_at_8: 0.7849\n",
        "rec_at_15: 0.9499\n",
        "prec_at_15: 0.5699\n",
        "\n",
        "evaluation finish in 39.12s\n",
        "file for evaluation: ./data/mimic3/test_full.csv\n",
        "\n",
        "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.4774, 0.6603, 0.5497, 0.5999, 0.8748\n",
        "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.6514, 0.8327, 0.7495, 0.7889, 0.9498\n",
        "rec_at_5: 0.5383\n",
        "prec_at_5: 0.8937\n",
        "rec_at_8: 0.7276\n",
        "prec_at_8: 0.7873\n",
        "rec_at_15: 0.9459\n",
        "prec_at_15: 0.5745\n",
        "\n",
        "saved metrics, params, model to directory ./models\\MultiResCNN_HierarchicalHyperbolic_Apr_11_01_53_58\n",
        "\n",
        "Training model at depth 1:\n",
        "EPOCH 0\n",
        "epoch finish in 563.96s, loss: 0.0921\n",
        "file for evaluation: ./data/mimic3/dev_full.csv\n",
        "\n",
        "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.1564, 0.2938, 0.1833, 0.2258, 0.8591\n",
        "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.4542, 0.7868, 0.5179, 0.6247, 0.9626\n",
        "rec_at_5: 0.3632\n",
        "prec_at_5: 0.8487\n",
        "rec_at_8: 0.5031\n",
        "prec_at_8: 0.7591\n",
        "rec_at_15: 0.6911\n",
        "prec_at_15: 0.5843\n",
        "\n",
        "evaluation finish in 41.13s\n",
        "saved metrics, params, model to directory ./models\\MultiResCNN_HierarchicalHyperbolic_Apr_11_01_53_58\n",
        "\n",
        "EPOCH 1\n",
        "epoch finish in 541.92s, loss: 0.0773\n",
        "file for evaluation: ./data/mimic3/dev_full.csv\n",
        "\n",
        "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.2085, 0.3408, 0.2426, 0.2834, 0.8844\n",
        "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.5019, 0.8126, 0.5676, 0.6683, 0.9697\n",
        "rec_at_5: 0.3798\n",
        "prec_at_5: 0.8792\n",
        "rec_at_8: 0.5325\n",
        "prec_at_8: 0.7986\n",
        "rec_at_15: 0.7237\n",
        "prec_at_15: 0.6121\n",
        "\n",
        "evaluation finish in 46.92s\n",
        "saved metrics, params, model to directory ./models\\MultiResCNN_HierarchicalHyperbolic_Apr_11_01_53_58\n",
        "\n",
        "EPOCH 2\n",
        "epoch finish in 431.01s, loss: 0.0719\n",
        "last epoch: testing on dev and test sets\n",
        "file for evaluation: ./data/mimic3/dev_full.csv\n",
        "\n",
        "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.2378, 0.3865, 0.2809, 0.3253, 0.9032\n",
        "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.5321, 0.8048, 0.6110, 0.6946, 0.9732\n",
        "rec_at_5: 0.3867\n",
        "prec_at_5: 0.8917\n",
        "rec_at_8: 0.5433\n",
        "prec_at_8: 0.8130\n",
        "rec_at_15: 0.7425\n",
        "prec_at_15: 0.6270\n",
        "\n",
        "evaluation finish in 43.82s\n",
        "file for evaluation: ./data/mimic3/test_full.csv\n",
        "\n",
        "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.2388, 0.4058, 0.2829, 0.3334, 0.8964\n",
        "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.5294, 0.8040, 0.6078, 0.6923, 0.9722\n",
        "rec_at_5: 0.3798\n",
        "prec_at_5: 0.8940\n",
        "rec_at_8: 0.5324\n",
        "prec_at_8: 0.8146\n",
        "rec_at_15: 0.7329\n",
        "prec_at_15: 0.6321\n",
        "\n",
        "saved metrics, params, model to directory ./models\\MultiResCNN_HierarchicalHyperbolic_Apr_11_01_53_58\n",
        "\n",
        "Training model at depth 2:\n",
        "EPOCH 0\n",
        "epoch finish in 569.98s, loss: 0.0290\n",
        "file for evaluation: ./data/mimic3/dev_full.csv\n",
        "\n",
        "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.0673, 0.1360, 0.0783, 0.0994, 0.8788\n",
        "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.3997, 0.7809, 0.4502, 0.5711, 0.9765\n",
        "rec_at_5: 0.3175\n",
        "prec_at_5: 0.8358\n",
        "rec_at_8: 0.4417\n",
        "prec_at_8: 0.7520\n",
        "rec_at_15: 0.6076\n",
        "prec_at_15: 0.5770\n",
        "\n",
        "evaluation finish in 41.62s\n",
        "saved metrics, params, model to directory ./models\\MultiResCNN_HierarchicalHyperbolic_Apr_11_01_53_58\n",
        "\n",
        "EPOCH 1\n",
        "epoch finish in 570.95s, loss: 0.0252\n",
        "file for evaluation: ./data/mimic3/dev_full.csv\n",
        "\n",
        "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.0940, 0.1677, 0.1128, 0.1349, 0.8987\n",
        "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.4446, 0.7701, 0.5127, 0.6156, 0.9807\n",
        "rec_at_5: 0.3286\n",
        "prec_at_5: 0.8585\n",
        "rec_at_8: 0.4622\n",
        "prec_at_8: 0.7793\n",
        "rec_at_15: 0.6370\n",
        "prec_at_15: 0.6045\n",
        "\n",
        "evaluation finish in 42.79s\n",
        "saved metrics, params, model to directory ./models\\MultiResCNN_HierarchicalHyperbolic_Apr_11_01_53_58\n",
        "\n",
        "EPOCH 2\n",
        "epoch finish in 572.00s, loss: 0.0238\n",
        "file for evaluation: ./data/mimic3/dev_full.csv\n",
        "\n",
        "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.1071, 0.1893, 0.1278, 0.1526, 0.9076\n",
        "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.4630, 0.7825, 0.5314, 0.6330, 0.9825\n",
        "rec_at_5: 0.3359\n",
        "prec_at_5: 0.8726\n",
        "rec_at_8: 0.4711\n",
        "prec_at_8: 0.7926\n",
        "rec_at_15: 0.6531\n",
        "prec_at_15: 0.6190\n",
        "\n",
        "evaluation finish in 43.98s\n",
        "saved metrics, params, model to directory ./models\\MultiResCNN_HierarchicalHyperbolic_Apr_11_01_53_58\n",
        "\n",
        "EPOCH 3\n",
        "epoch finish in 575.48s, loss: 0.0228\n",
        "file for evaluation: ./data/mimic3/dev_full.csv\n",
        "\n",
        "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.1225, 0.2023, 0.1482, 0.1711, 0.9157\n",
        "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.4782, 0.7681, 0.5589, 0.6470, 0.9838\n",
        "rec_at_5: 0.3376\n",
        "prec_at_5: 0.8763\n",
        "rec_at_8: 0.4766\n",
        "prec_at_8: 0.7992\n",
        "rec_at_15: 0.6623\n",
        "prec_at_15: 0.6269\n",
        "\n",
        "evaluation finish in 40.38s\n",
        "saved metrics, params, model to directory ./models\\MultiResCNN_HierarchicalHyperbolic_Apr_11_01_53_58\n",
        "\n",
        "EPOCH 4\n",
        "epoch finish in 588.87s, loss: 0.0221\n",
        "last epoch: testing on dev and test sets\n",
        "file for evaluation: ./data/mimic3/dev_full.csv\n",
        "\n",
        "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.1265, 0.2130, 0.1533, 0.1783, 0.9222\n",
        "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.4851, 0.7770, 0.5635, 0.6533, 0.9848\n",
        "rec_at_5: 0.3401\n",
        "prec_at_5: 0.8804\n",
        "rec_at_8: 0.4795\n",
        "prec_at_8: 0.8028\n",
        "rec_at_15: 0.6680\n",
        "prec_at_15: 0.6318\n",
        "\n",
        "evaluation finish in 41.85s\n",
        "file for evaluation: ./data/mimic3/test_full.csv\n",
        "\n",
        "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.1307, 0.2286, 0.1570, 0.1861, 0.9199\n",
        "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.4834, 0.7742, 0.5627, 0.6517, 0.9845\n",
        "rec_at_5: 0.3300\n",
        "prec_at_5: 0.8789\n",
        "rec_at_8: 0.4670\n",
        "prec_at_8: 0.8055\n",
        "rec_at_15: 0.6577\n",
        "prec_at_15: 0.6405\n",
        "\n",
        "saved metrics, params, model to directory ./models\\MultiResCNN_HierarchicalHyperbolic_Apr_11_01_53_58\n",
        "\n",
        "Training model at depth 3:\n",
        "EPOCH 0\n",
        "epoch finish in 655.62s, loss: 0.0088\n",
        "file for evaluation: ./data/mimic3/dev_full.csv\n",
        "\n",
        "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.0287, 0.0577, 0.0345, 0.0432, 0.9113\n",
        "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.3380, 0.7427, 0.3829, 0.5053, 0.9853\n",
        "rec_at_5: 0.2792\n",
        "prec_at_5: 0.7874\n",
        "rec_at_8: 0.3891\n",
        "prec_at_8: 0.7078\n",
        "rec_at_15: 0.5413\n",
        "prec_at_15: 0.5501\n",
        "\n",
        "evaluation finish in 39.69s\n",
        "saved metrics, params, model to directory ./models\\MultiResCNN_HierarchicalHyperbolic_Apr_11_01_53_58\n",
        "\n",
        "EPOCH 1\n",
        "epoch finish in 655.70s, loss: 0.0076\n",
        "file for evaluation: ./data/mimic3/dev_full.csv\n",
        "\n",
        "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.0409, 0.0733, 0.0502, 0.0596, 0.9209\n",
        "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.3815, 0.7320, 0.4434, 0.5522, 0.9869\n",
        "rec_at_5: 0.2914\n",
        "prec_at_5: 0.8179\n",
        "rec_at_8: 0.4068\n",
        "prec_at_8: 0.7370\n",
        "rec_at_15: 0.5681\n",
        "prec_at_15: 0.5773\n",
        "\n",
        "evaluation finish in 39.49s\n",
        "saved metrics, params, model to directory ./models\\MultiResCNN_HierarchicalHyperbolic_Apr_11_01_53_58\n",
        "\n",
        "EPOCH 2\n",
        "epoch finish in 669.01s, loss: 0.0072\n",
        "file for evaluation: ./data/mimic3/dev_full.csv\n",
        "\n",
        "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.0460, 0.0800, 0.0559, 0.0658, 0.9268\n",
        "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.3984, 0.7350, 0.4652, 0.5698, 0.9880\n",
        "rec_at_5: 0.2953\n",
        "prec_at_5: 0.8275\n",
        "rec_at_8: 0.4140\n",
        "prec_at_8: 0.7482\n",
        "rec_at_15: 0.5791\n",
        "prec_at_15: 0.5880\n",
        "\n",
        "evaluation finish in 41.74s\n",
        "saved metrics, params, model to directory ./models\\MultiResCNN_HierarchicalHyperbolic_Apr_11_01_53_58\n",
        "\n",
        "EPOCH 3\n",
        "epoch finish in 660.83s, loss: 0.0070\n",
        "file for evaluation: ./data/mimic3/dev_full.csv\n",
        "\n",
        "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.0473, 0.0844, 0.0556, 0.0670, 0.9297\n",
        "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.4001, 0.7518, 0.4609, 0.5715, 0.9886\n",
        "rec_at_5: 0.2991\n",
        "prec_at_5: 0.8362\n",
        "rec_at_8: 0.4217\n",
        "prec_at_8: 0.7604\n",
        "rec_at_15: 0.5879\n",
        "prec_at_15: 0.5964\n",
        "\n",
        "evaluation finish in 39.21s\n",
        "saved metrics, params, model to directory ./models\\MultiResCNN_HierarchicalHyperbolic_Apr_11_01_53_58\n",
        "\n",
        "EPOCH 4\n",
        "epoch finish in 665.44s, loss: 0.0068\n",
        "file for evaluation: ./data/mimic3/dev_full.csv\n",
        "\n",
        "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.0539, 0.0905, 0.0653, 0.0759, 0.9335\n",
        "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.4132, 0.7398, 0.4835, 0.5848, 0.9891\n",
        "rec_at_5: 0.2998\n",
        "prec_at_5: 0.8374\n",
        "rec_at_8: 0.4240\n",
        "prec_at_8: 0.7641\n",
        "rec_at_15: 0.5917\n",
        "prec_at_15: 0.6001\n",
        "\n",
        "evaluation finish in 39.30s\n",
        "saved metrics, params, model to directory ./models\\MultiResCNN_HierarchicalHyperbolic_Apr_11_01_53_58\n",
        "\n",
        "EPOCH 5\n",
        "epoch finish in 657.87s, loss: 0.0066\n",
        "file for evaluation: ./data/mimic3/dev_full.csv\n",
        "\n",
        "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.0548, 0.0955, 0.0642, 0.0768, 0.9353\n",
        "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.4091, 0.7570, 0.4709, 0.5806, 0.9894\n",
        "rec_at_5: 0.3014\n",
        "prec_at_5: 0.8406\n",
        "rec_at_8: 0.4267\n",
        "prec_at_8: 0.7679\n",
        "rec_at_15: 0.5959\n",
        "prec_at_15: 0.6036\n",
        "\n",
        "evaluation finish in 38.75s\n",
        "saved metrics, params, model to directory ./models\\MultiResCNN_HierarchicalHyperbolic_Apr_11_01_53_58\n",
        "\n",
        "EPOCH 6\n",
        "epoch finish in 663.57s, loss: 0.0065\n",
        "file for evaluation: ./data/mimic3/dev_full.csv\n",
        "\n",
        "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.0605, 0.1011, 0.0724, 0.0844, 0.9373\n",
        "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.4248, 0.7432, 0.4979, 0.5963, 0.9897\n",
        "rec_at_5: 0.3034\n",
        "prec_at_5: 0.8441\n",
        "rec_at_8: 0.4299\n",
        "prec_at_8: 0.7728\n",
        "rec_at_15: 0.6009\n",
        "prec_at_15: 0.6091\n",
        "\n",
        "evaluation finish in 42.70s\n",
        "saved metrics, params, model to directory ./models\\MultiResCNN_HierarchicalHyperbolic_Apr_11_01_53_58\n",
        "\n",
        "EPOCH 7\n",
        "epoch finish in 655.75s, loss: 0.0064\n",
        "file for evaluation: ./data/mimic3/dev_full.csv\n",
        "\n",
        "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.0642, 0.1051, 0.0772, 0.0890, 0.9390\n",
        "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.4284, 0.7364, 0.5060, 0.5998, 0.9900\n",
        "rec_at_5: 0.3031\n",
        "prec_at_5: 0.8454\n",
        "rec_at_8: 0.4305\n",
        "prec_at_8: 0.7732\n",
        "rec_at_15: 0.6041\n",
        "prec_at_15: 0.6121\n",
        "\n",
        "evaluation finish in 40.45s\n",
        "saved metrics, params, model to directory ./models\\MultiResCNN_HierarchicalHyperbolic_Apr_11_01_53_58\n",
        "\n",
        "EPOCH 8\n",
        "epoch finish in 665.91s, loss: 0.0063\n",
        "file for evaluation: ./data/mimic3/dev_full.csv\n",
        "\n",
        "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.0648, 0.1064, 0.0774, 0.0896, 0.9399\n",
        "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.4289, 0.7469, 0.5019, 0.6004, 0.9902\n",
        "rec_at_5: 0.3047\n",
        "prec_at_5: 0.8472\n",
        "rec_at_8: 0.4330\n",
        "prec_at_8: 0.7769\n",
        "rec_at_15: 0.6069\n",
        "prec_at_15: 0.6146\n",
        "\n",
        "evaluation finish in 41.79s\n",
        "saved metrics, params, model to directory ./models\\MultiResCNN_HierarchicalHyperbolic_Apr_11_01_53_58\n",
        "\n",
        "EPOCH 9\n",
        "epoch finish in 672.56s, loss: 0.0062\n",
        "last epoch: testing on dev and test sets\n",
        "file for evaluation: ./data/mimic3/dev_full.csv\n",
        "\n",
        "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.0662, 0.1086, 0.0785, 0.0911, 0.9406\n",
        "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.4281, 0.7465, 0.5010, 0.5996, 0.9903\n",
        "rec_at_5: 0.3041\n",
        "prec_at_5: 0.8466\n",
        "rec_at_8: 0.4314\n",
        "prec_at_8: 0.7757\n",
        "rec_at_15: 0.6093\n",
        "prec_at_15: 0.6173\n",
        "\n",
        "evaluation finish in 40.50s\n",
        "file for evaluation: ./data/mimic3/test_full.csv\n",
        "\n",
        "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.0713, 0.1257, 0.0857, 0.1019, 0.9408\n",
        "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.4253, 0.7438, 0.4983, 0.5968, 0.9904\n",
        "rec_at_5: 0.2968\n",
        "prec_at_5: 0.8491\n",
        "rec_at_8: 0.4185\n",
        "prec_at_8: 0.7754\n",
        "rec_at_15: 0.5931\n",
        "prec_at_15: 0.6202\n",
        "\n",
        "saved metrics, params, model to directory ./models\\MultiResCNN_HierarchicalHyperbolic_Apr_11_01_53_58\n",
        "\n",
        "Training model at depth 4:\n",
        "EPOCH 0\n",
        "epoch finish in 747.65s, loss: 0.0049\n",
        "file for evaluation: ./data/mimic3/dev_full.csv\n",
        "\n",
        "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.0319, 0.0551, 0.0390, 0.0457, 0.9390\n",
        "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.3474, 0.7078, 0.4055, 0.5156, 0.9892\n",
        "rec_at_5: 0.2804\n",
        "prec_at_5: 0.7982\n",
        "rec_at_8: 0.3892\n",
        "prec_at_8: 0.7136\n",
        "rec_at_15: 0.5413\n",
        "prec_at_15: 0.5577\n",
        "\n",
        "evaluation finish in 45.10s\n",
        "saved metrics, params, model to directory ./models\\MultiResCNN_HierarchicalHyperbolic_Apr_11_01_53_58\n",
        "\n",
        "EPOCH 1\n",
        "epoch finish in 741.50s, loss: 0.0045\n",
        "file for evaluation: ./data/mimic3/dev_full.csv\n",
        "\n",
        "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.0374, 0.0619, 0.0454, 0.0524, 0.9427\n",
        "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.3633, 0.7134, 0.4254, 0.5330, 0.9898\n",
        "rec_at_5: 0.2839\n",
        "prec_at_5: 0.8047\n",
        "rec_at_8: 0.3978\n",
        "prec_at_8: 0.7262\n",
        "rec_at_15: 0.5526\n",
        "prec_at_15: 0.5686\n",
        "\n",
        "evaluation finish in 44.71s\n",
        "saved metrics, params, model to directory ./models\\MultiResCNN_HierarchicalHyperbolic_Apr_11_01_53_58\n",
        "\n",
        "EPOCH 2\n",
        "epoch finish in 750.85s, loss: 0.0044\n",
        "file for evaluation: ./data/mimic3/dev_full.csv\n",
        "\n",
        "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.0420, 0.0675, 0.0518, 0.0586, 0.9444\n",
        "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.3744, 0.6990, 0.4463, 0.5448, 0.9902\n",
        "rec_at_5: 0.2877\n",
        "prec_at_5: 0.8132\n",
        "rec_at_8: 0.3984\n",
        "prec_at_8: 0.7292\n",
        "rec_at_15: 0.5559\n",
        "prec_at_15: 0.5731\n",
        "\n",
        "evaluation finish in 45.06s\n",
        "saved metrics, params, model to directory ./models\\MultiResCNN_HierarchicalHyperbolic_Apr_11_01_53_58\n",
        "\n",
        "EPOCH 3\n",
        "epoch finish in 737.98s, loss: 0.0043\n",
        "file for evaluation: ./data/mimic3/dev_full.csv\n",
        "\n",
        "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.0419, 0.0683, 0.0505, 0.0581, 0.9452\n",
        "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.3742, 0.7223, 0.4370, 0.5446, 0.9904\n",
        "rec_at_5: 0.2885\n",
        "prec_at_5: 0.8166\n",
        "rec_at_8: 0.4018\n",
        "prec_at_8: 0.7341\n",
        "rec_at_15: 0.5621\n",
        "prec_at_15: 0.5790\n",
        "\n",
        "evaluation finish in 54.14s\n",
        "saved metrics, params, model to directory ./models\\MultiResCNN_HierarchicalHyperbolic_Apr_11_01_53_58\n",
        "\n",
        "EPOCH 4\n",
        "epoch finish in 744.83s, loss: 0.0042\n",
        "file for evaluation: ./data/mimic3/dev_full.csv\n",
        "\n",
        "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.0443, 0.0719, 0.0536, 0.0614, 0.9461\n",
        "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.3808, 0.7173, 0.4480, 0.5516, 0.9906\n",
        "rec_at_5: 0.2876\n",
        "prec_at_5: 0.8159\n",
        "rec_at_8: 0.4043\n",
        "prec_at_8: 0.7394\n",
        "rec_at_15: 0.5665\n",
        "prec_at_15: 0.5843\n",
        "\n",
        "evaluation finish in 50.71s\n",
        "saved metrics, params, model to directory ./models\\MultiResCNN_HierarchicalHyperbolic_Apr_11_01_53_58\n",
        "\n",
        "EPOCH 5\n",
        "epoch finish in 756.30s, loss: 0.0041\n",
        "file for evaluation: ./data/mimic3/dev_full.csv\n",
        "\n",
        "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.0465, 0.0734, 0.0564, 0.0638, 0.9464\n",
        "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.3870, 0.7097, 0.4598, 0.5581, 0.9906\n",
        "rec_at_5: 0.2900\n",
        "prec_at_5: 0.8206\n",
        "rec_at_8: 0.4039\n",
        "prec_at_8: 0.7397\n",
        "rec_at_15: 0.5668\n",
        "prec_at_15: 0.5843\n",
        "\n",
        "evaluation finish in 45.53s\n",
        "saved metrics, params, model to directory ./models\\MultiResCNN_HierarchicalHyperbolic_Apr_11_01_53_58\n",
        "\n",
        "EPOCH 6\n",
        "epoch finish in 740.03s, loss: 0.0041\n",
        "file for evaluation: ./data/mimic3/dev_full.csv\n",
        "\n",
        "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.0470, 0.0758, 0.0563, 0.0646, 0.9472\n",
        "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.3847, 0.7192, 0.4527, 0.5557, 0.9907\n",
        "rec_at_5: 0.2889\n",
        "prec_at_5: 0.8199\n",
        "rec_at_8: 0.4050\n",
        "prec_at_8: 0.7416\n",
        "rec_at_15: 0.5715\n",
        "prec_at_15: 0.5882\n",
        "\n",
        "evaluation finish in 51.47s\n",
        "saved metrics, params, model to directory ./models\\MultiResCNN_HierarchicalHyperbolic_Apr_11_01_53_58\n",
        "\n",
        "EPOCH 7\n",
        "epoch finish in 746.29s, loss: 0.0040\n",
        "file for evaluation: ./data/mimic3/dev_full.csv\n",
        "\n",
        "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.0516, 0.0787, 0.0627, 0.0698, 0.9476\n",
        "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.3931, 0.7088, 0.4689, 0.5644, 0.9908\n",
        "rec_at_5: 0.2914\n",
        "prec_at_5: 0.8254\n",
        "rec_at_8: 0.4065\n",
        "prec_at_8: 0.7454\n",
        "rec_at_15: 0.5710\n",
        "prec_at_15: 0.5884\n",
        "\n",
        "evaluation finish in 45.55s\n",
        "saved metrics, params, model to directory ./models\\MultiResCNN_HierarchicalHyperbolic_Apr_11_01_53_58\n",
        "\n",
        "EPOCH 8\n",
        "epoch finish in 754.57s, loss: 0.0040\n",
        "file for evaluation: ./data/mimic3/dev_full.csv\n",
        "\n",
        "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.0494, 0.0785, 0.0593, 0.0675, 0.9476\n",
        "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.3887, 0.7188, 0.4585, 0.5598, 0.9908\n",
        "rec_at_5: 0.2895\n",
        "prec_at_5: 0.8189\n",
        "rec_at_8: 0.4063\n",
        "prec_at_8: 0.7437\n",
        "rec_at_15: 0.5726\n",
        "prec_at_15: 0.5897\n",
        "\n",
        "evaluation finish in 44.60s\n",
        "saved metrics, params, model to directory ./models\\MultiResCNN_HierarchicalHyperbolic_Apr_11_01_53_58\n",
        "\n",
        "EPOCH 9\n",
        "epoch finish in 752.25s, loss: 0.0039\n",
        "file for evaluation: ./data/mimic3/dev_full.csv\n",
        "\n",
        "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.0534, 0.0821, 0.0652, 0.0727, 0.9483\n",
        "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.3989, 0.7026, 0.4799, 0.5703, 0.9909\n",
        "rec_at_5: 0.2905\n",
        "prec_at_5: 0.8221\n",
        "rec_at_8: 0.4076\n",
        "prec_at_8: 0.7450\n",
        "rec_at_15: 0.5743\n",
        "prec_at_15: 0.5913\n",
        "\n",
        "evaluation finish in 50.71s\n",
        "saved metrics, params, model to directory ./models\\MultiResCNN_HierarchicalHyperbolic_Apr_11_01_53_58\n",
        "\n",
        "EPOCH 10\n",
        "epoch finish in 761.71s, loss: 0.0039\n",
        "file for evaluation: ./data/mimic3/dev_full.csv\n",
        "\n",
        "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.0534, 0.0818, 0.0657, 0.0729, 0.9488\n",
        "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.3965, 0.7000, 0.4776, 0.5678, 0.9911\n",
        "rec_at_5: 0.2892\n",
        "prec_at_5: 0.8202\n",
        "rec_at_8: 0.4073\n",
        "prec_at_8: 0.7460\n",
        "rec_at_15: 0.5712\n",
        "prec_at_15: 0.5893\n",
        "\n",
        "evaluation finish in 45.86s\n",
        "saved metrics, params, model to directory ./models\\MultiResCNN_HierarchicalHyperbolic_Apr_11_01_53_58\n",
        "\n",
        "EPOCH 11\n",
        "epoch finish in 742.25s, loss: 0.0039\n",
        "file for evaluation: ./data/mimic3/dev_full.csv\n",
        "\n",
        "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.0539, 0.0827, 0.0653, 0.0730, 0.9487\n",
        "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.3981, 0.7053, 0.4776, 0.5695, 0.9910\n",
        "rec_at_5: 0.2909\n",
        "prec_at_5: 0.8250\n",
        "rec_at_8: 0.4070\n",
        "prec_at_8: 0.7450\n",
        "rec_at_15: 0.5729\n",
        "prec_at_15: 0.5909\n",
        "\n",
        "evaluation finish in 45.07s\n",
        "saved metrics, params, model to directory ./models\\MultiResCNN_HierarchicalHyperbolic_Apr_11_01_53_58\n",
        "\n",
        "EPOCH 12\n",
        "epoch finish in 747.28s, loss: 0.0038\n",
        "file for evaluation: ./data/mimic3/dev_full.csv\n",
        "\n",
        "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.0571, 0.0866, 0.0697, 0.0772, 0.9483\n",
        "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.4015, 0.6969, 0.4864, 0.5730, 0.9910\n",
        "rec_at_5: 0.2916\n",
        "prec_at_5: 0.8269\n",
        "rec_at_8: 0.4091\n",
        "prec_at_8: 0.7482\n",
        "rec_at_15: 0.5741\n",
        "prec_at_15: 0.5919\n",
        "\n",
        "evaluation finish in 55.47s\n",
        "saved metrics, params, model to directory ./models\\MultiResCNN_HierarchicalHyperbolic_Apr_11_01_53_58\n",
        "\n",
        "EPOCH 13\n",
        "epoch finish in 748.36s, loss: 0.0038\n",
        "file for evaluation: ./data/mimic3/dev_full.csv\n",
        "\n",
        "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.0583, 0.0876, 0.0719, 0.0790, 0.9482\n",
        "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.4028, 0.6910, 0.4912, 0.5742, 0.9910\n",
        "rec_at_5: 0.2914\n",
        "prec_at_5: 0.8239\n",
        "rec_at_8: 0.4082\n",
        "prec_at_8: 0.7462\n",
        "rec_at_15: 0.5731\n",
        "prec_at_15: 0.5909\n",
        "\n",
        "evaluation finish in 45.48s\n",
        "saved metrics, params, model to directory ./models\\MultiResCNN_HierarchicalHyperbolic_Apr_11_01_53_58\n",
        "\n",
        "EPOCH 14\n",
        "epoch finish in 756.94s, loss: 0.0038\n",
        "file for evaluation: ./data/mimic3/dev_full.csv\n",
        "\n",
        "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.0553, 0.0853, 0.0668, 0.0749, 0.9482\n",
        "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.3940, 0.7091, 0.4700, 0.5653, 0.9909\n",
        "rec_at_5: 0.2908\n",
        "prec_at_5: 0.8250\n",
        "rec_at_8: 0.4074\n",
        "prec_at_8: 0.7456\n",
        "rec_at_15: 0.5749\n",
        "prec_at_15: 0.5926\n",
        "\n",
        "evaluation finish in 47.22s\n",
        "saved metrics, params, model to directory ./models\\MultiResCNN_HierarchicalHyperbolic_Apr_11_01_53_58\n",
        "\n",
        "EPOCH 15\n",
        "epoch finish in 739.42s, loss: 0.0037\n",
        "file for evaluation: ./data/mimic3/dev_full.csv\n",
        "\n",
        "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.0563, 0.0873, 0.0684, 0.0767, 0.9480\n",
        "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.3990, 0.7047, 0.4792, 0.5704, 0.9909\n",
        "rec_at_5: 0.2909\n",
        "prec_at_5: 0.8245\n",
        "rec_at_8: 0.4089\n",
        "prec_at_8: 0.7466\n",
        "rec_at_15: 0.5733\n",
        "prec_at_15: 0.5912\n",
        "\n",
        "evaluation finish in 50.21s\n",
        "saved metrics, params, model to directory ./models\\MultiResCNN_HierarchicalHyperbolic_Apr_11_01_53_58\n",
        "\n",
        "EPOCH 16\n",
        "epoch finish in 753.56s, loss: 0.0037\n",
        "file for evaluation: ./data/mimic3/dev_full.csv\n",
        "\n",
        "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.0564, 0.0868, 0.0680, 0.0763, 0.9480\n",
        "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.3968, 0.7053, 0.4757, 0.5682, 0.9908\n",
        "rec_at_5: 0.2908\n",
        "prec_at_5: 0.8261\n",
        "rec_at_8: 0.4088\n",
        "prec_at_8: 0.7472\n",
        "rec_at_15: 0.5751\n",
        "prec_at_15: 0.5931\n",
        "\n",
        "evaluation finish in 46.98s\n",
        "saved metrics, params, model to directory ./models\\MultiResCNN_HierarchicalHyperbolic_Apr_11_01_53_58\n",
        "\n",
        "EPOCH 17\n",
        "epoch finish in 745.43s, loss: 0.0037\n",
        "file for evaluation: ./data/mimic3/dev_full.csv\n",
        "\n",
        "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.0578, 0.0876, 0.0702, 0.0779, 0.9480\n",
        "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.4005, 0.6949, 0.4860, 0.5719, 0.9908\n",
        "rec_at_5: 0.2899\n",
        "prec_at_5: 0.8244\n",
        "rec_at_8: 0.4085\n",
        "prec_at_8: 0.7472\n",
        "rec_at_15: 0.5744\n",
        "prec_at_15: 0.5920\n",
        "\n",
        "evaluation finish in 46.18s\n",
        "saved metrics, params, model to directory ./models\\MultiResCNN_HierarchicalHyperbolic_Apr_11_01_53_58\n",
        "\n",
        "EPOCH 18\n",
        "epoch finish in 739.14s, loss: 0.0036\n",
        "file for evaluation: ./data/mimic3/dev_full.csv\n",
        "\n",
        "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.0595, 0.0888, 0.0727, 0.0800, 0.9479\n",
        "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.4022, 0.6952, 0.4883, 0.5737, 0.9907\n",
        "rec_at_5: 0.2901\n",
        "prec_at_5: 0.8224\n",
        "rec_at_8: 0.4074\n",
        "prec_at_8: 0.7452\n",
        "rec_at_15: 0.5736\n",
        "prec_at_15: 0.5914\n",
        "\n",
        "evaluation finish in 44.83s\n",
        "saved metrics, params, model to directory ./models\\MultiResCNN_HierarchicalHyperbolic_Apr_11_01_53_58\n",
        "\n",
        "EPOCH 19\n",
        "epoch finish in 747.56s, loss: 0.0036\n",
        "file for evaluation: ./data/mimic3/dev_full.csv\n",
        "\n",
        "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.0580, 0.0888, 0.0709, 0.0788, 0.9480\n",
        "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.4019, 0.6938, 0.4886, 0.5734, 0.9907\n",
        "rec_at_5: 0.2904\n",
        "prec_at_5: 0.8227\n",
        "rec_at_8: 0.4087\n",
        "prec_at_8: 0.7478\n",
        "rec_at_15: 0.5731\n",
        "prec_at_15: 0.5911\n",
        "\n",
        "evaluation finish in 45.25s\n",
        "saved metrics, params, model to directory ./models\\MultiResCNN_HierarchicalHyperbolic_Apr_11_01_53_58\n",
        "\n",
        "EPOCH 20\n",
        "epoch finish in 748.43s, loss: 0.0036\n",
        "file for evaluation: ./data/mimic3/dev_full.csv\n",
        "\n",
        "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.0590, 0.0895, 0.0714, 0.0794, 0.9473\n",
        "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.4016, 0.6992, 0.4855, 0.5730, 0.9907\n",
        "rec_at_5: 0.2890\n",
        "prec_at_5: 0.8186\n",
        "rec_at_8: 0.4082\n",
        "prec_at_8: 0.7465\n",
        "rec_at_15: 0.5739\n",
        "prec_at_15: 0.5921\n",
        "\n",
        "evaluation finish in 44.61s\n",
        "saved metrics, params, model to directory ./models\\MultiResCNN_HierarchicalHyperbolic_Apr_11_01_53_58\n",
        "\n",
        "EPOCH 21\n",
        "epoch finish in 751.02s, loss: 0.0036\n",
        "file for evaluation: ./data/mimic3/dev_full.csv\n",
        "\n",
        "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.0616, 0.0917, 0.0755, 0.0828, 0.9472\n",
        "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.4043, 0.6892, 0.4944, 0.5758, 0.9907\n",
        "rec_at_5: 0.2891\n",
        "prec_at_5: 0.8191\n",
        "rec_at_8: 0.4069\n",
        "prec_at_8: 0.7440\n",
        "rec_at_15: 0.5729\n",
        "prec_at_15: 0.5916\n",
        "\n",
        "evaluation finish in 48.28s\n",
        "saved metrics, params, model to directory ./models\\MultiResCNN_HierarchicalHyperbolic_Apr_11_01_53_58\n",
        "\n",
        "EPOCH 22\n",
        "epoch finish in 756.25s, loss: 0.0035\n",
        "file for evaluation: ./data/mimic3/dev_full.csv\n",
        "\n",
        "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.0610, 0.0905, 0.0746, 0.0818, 0.9469\n",
        "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.4027, 0.6868, 0.4933, 0.5742, 0.9906\n",
        "rec_at_5: 0.2897\n",
        "prec_at_5: 0.8199\n",
        "rec_at_8: 0.4078\n",
        "prec_at_8: 0.7456\n",
        "rec_at_15: 0.5752\n",
        "prec_at_15: 0.5926\n",
        "\n",
        "evaluation finish in 45.09s\n",
        "saved metrics, params, model to directory ./models\\MultiResCNN_HierarchicalHyperbolic_Apr_11_01_53_58\n",
        "\n",
        "prec_at_8 hasn't improved in 10 epochs, early stopping...\n",
        "loading pretrained embeddings from ./data/mimic3/processed_full_100.embed\n",
        "adding unk embedding\n",
        "file for evaluation: ./data/mimic3/dev_full.csv\n",
        "\n",
        "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.0571, 0.0866, 0.0697, 0.0772, 0.9483\n",
        "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.4015, 0.6969, 0.4864, 0.5730, 0.9910\n",
        "rec_at_5: 0.2916\n",
        "prec_at_5: 0.8269\n",
        "rec_at_8: 0.4091\n",
        "prec_at_8: 0.7482\n",
        "rec_at_15: 0.5741\n",
        "prec_at_15: 0.5919\n",
        "\n",
        "evaluation finish in 43.99s\n",
        "file for evaluation: ./data/mimic3/test_full.csv\n",
        "\n",
        "[MACRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.0639, 0.1046, 0.0799, 0.0906, 0.9478\n",
        "[MICRO] accuracy, precision, recall, f-measure, AUC\n",
        "0.3955, 0.6912, 0.4804, 0.5669, 0.9907\n",
        "rec_at_5: 0.2804\n",
        "prec_at_5: 0.8226\n",
        "rec_at_8: 0.3954\n",
        "prec_at_8: 0.7498\n",
        "rec_at_15: 0.5592\n",
        "prec_at_15: 0.5970\n",
        "\n",
        "saved metrics, params, model to directory C:\\Users\\test\\UIUC\\HiCu-ICD-UIUC-Evaluation-Private\\models\\MultiResCNN_HierarchicalHyperbolic_Apr_11_01_53_58\n",
        "```"
      ],
      "metadata": {
        "id": "MzirEkDh1HIp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation\n",
        "\n",
        "## Metrics Used in Evaluation:\n",
        "- **AUC (Area Under the Curve):** Utilized in both micro-averaged and macro-averaged forms, this metric measures the overall prediction performance across all labels.\n",
        "- **F1 Score:** Reported in both micro-averaged and macro-averaged forms, it indicates the balance between precision and recall.\n",
        "- **Precision@K (P@K):** This metric assesses the proportion of correctly predicted labels in the top-K predictions, essential for practical applications where only the top few predictions may be considered.\n",
        "\n",
        "## Performance Results:\n",
        "- The HiCu method was tested on several model architectures, showing improvements in AUC and F1 scores over baseline models without curriculum learning.\n",
        "- Notable enhancements were particularly evident for rare labels, addressing the challenge of imbalanced datasets prevalent in medical coding.\n",
        "- An asymmetric loss function was employed to handle label imbalance more effectively, leading to superior performance on rare and infrequent labels.\n",
        "- Extensive testing was conducted on the MIMIC-III dataset using ICD-9 codes, establishing the method's effectiveness on a standard dataset for medical coding research.\n",
        "\n",
        "\n",
        "## Implementation Code\n",
        "\n",
        "**Implementation of Metrics: AUC, F1, and Precision@K — The code snippet below is not yet compatible with Google Colab but functions correctly on the dedicated machine used for testing and training. I am working to make this operational in Google Colab within the next few days.**"
      ],
      "metadata": {
        "id": "E8tGHVz-yag5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_metrics(metrics):\n",
        "    print()\n",
        "    if \"auc_macro\" in metrics.keys():\n",
        "        print(\"[MACRO] accuracy, precision, recall, f-measure, AUC\")\n",
        "        print(\"%.4f, %.4f, %.4f, %.4f, %.4f\" % (metrics[\"acc_macro\"], metrics[\"prec_macro\"], metrics[\"rec_macro\"], metrics[\"f1_macro\"], metrics[\"auc_macro\"]))\n",
        "    else:\n",
        "        print(\"[MACRO] accuracy, precision, recall, f-measure\")\n",
        "        print(\"%.4f, %.4f, %.4f, %.4f\" % (metrics[\"acc_macro\"], metrics[\"prec_macro\"], metrics[\"rec_macro\"], metrics[\"f1_macro\"]))\n",
        "\n",
        "    if \"auc_micro\" in metrics.keys():\n",
        "        print(\"[MICRO] accuracy, precision, recall, f-measure, AUC\")\n",
        "        print(\"%.4f, %.4f, %.4f, %.4f, %.4f\" % (metrics[\"acc_micro\"], metrics[\"prec_micro\"], metrics[\"rec_micro\"], metrics[\"f1_micro\"], metrics[\"auc_micro\"]))\n",
        "    else:\n",
        "        print(\"[MICRO] accuracy, precision, recall, f-measure\")\n",
        "        print(\"%.4f, %.4f, %.4f, %.4f\" % (metrics[\"acc_micro\"], metrics[\"prec_micro\"], metrics[\"rec_micro\"], metrics[\"f1_micro\"]))\n",
        "    for metric, val in metrics.items():\n",
        "        if metric.find(\"rec_at\") != -1:\n",
        "            print(\"%s: %.4f\" % (metric, val))\n",
        "    print()\n",
        "\n",
        "def union_size(yhat, y, axis):\n",
        "    #axis=0 for label-level union (macro). axis=1 for instance-level\n",
        "    return np.logical_or(yhat, y).sum(axis=axis).astype(float)\n",
        "\n",
        "def intersect_size(yhat, y, axis):\n",
        "    #axis=0 for label-level union (macro). axis=1 for instance-level\n",
        "    return np.logical_and(yhat, y).sum(axis=axis).astype(float)\n",
        "\n",
        "def macro_accuracy(yhat, y):\n",
        "    num = intersect_size(yhat, y, 0) / (union_size(yhat, y, 0) + 1e-10)\n",
        "    return np.mean(num)\n",
        "\n",
        "def macro_precision(yhat, y):\n",
        "    num = intersect_size(yhat, y, 0) / (yhat.sum(axis=0) + 1e-10)\n",
        "    return np.mean(num)\n",
        "\n",
        "def macro_recall(yhat, y):\n",
        "    num = intersect_size(yhat, y, 0) / (y.sum(axis=0) + 1e-10)\n",
        "    return np.mean(num)\n",
        "\n",
        "def macro_f1(yhat, y):\n",
        "    prec = macro_precision(yhat, y)\n",
        "    rec = macro_recall(yhat, y)\n",
        "    if prec + rec == 0:\n",
        "        f1 = 0.\n",
        "    else:\n",
        "        f1 = 2*(prec*rec)/(prec+rec)\n",
        "    return f1\n",
        "\n",
        "\n",
        "def all_macro(yhat, y):\n",
        "    return macro_accuracy(yhat, y), macro_precision(yhat, y), macro_recall(yhat, y), macro_f1(yhat, y)\n",
        "\n",
        "def micro_accuracy(yhatmic, ymic):\n",
        "    return intersect_size(yhatmic, ymic, 0) / (union_size(yhatmic, ymic, 0) + 1e-10)\n",
        "\n",
        "def micro_precision(yhatmic, ymic):\n",
        "    return intersect_size(yhatmic, ymic, 0) / (yhatmic.sum(axis=0) + 1e-10)\n",
        "\n",
        "def micro_recall(yhatmic, ymic):\n",
        "    return intersect_size(yhatmic, ymic, 0) / (ymic.sum(axis=0) + 1e-10)\n",
        "\n",
        "def micro_f1(yhatmic, ymic):\n",
        "    prec = micro_precision(yhatmic, ymic)\n",
        "    rec = micro_recall(yhatmic, ymic)\n",
        "    if prec + rec == 0:\n",
        "        f1 = 0.\n",
        "    else:\n",
        "        f1 = 2 * (prec * rec) / (prec + rec)\n",
        "    return f1\n",
        "\n",
        "def all_micro(yhatmic, ymic):\n",
        "    return micro_accuracy(yhatmic, ymic), micro_precision(yhatmic, ymic), micro_recall(yhatmic, ymic), micro_f1(yhatmic, ymic)\n",
        "\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "def auc_metrics(yhat_raw, y, ymic):\n",
        "    if yhat_raw.shape[0] <= 1:\n",
        "        return\n",
        "    fpr = {}\n",
        "    tpr = {}\n",
        "    roc_auc = {}\n",
        "    #get AUC for each label individually\n",
        "    relevant_labels = []\n",
        "    auc_labels = {}\n",
        "    for i in range(y.shape[1]):\n",
        "        #only if there are true positives for this label\n",
        "        if y[:,i].sum() > 0:\n",
        "            fpr[i], tpr[i], _ = roc_curve(y[:,i], yhat_raw[:,i])\n",
        "            if len(fpr[i]) > 1 and len(tpr[i]) > 1:\n",
        "                auc_score = auc(fpr[i], tpr[i])\n",
        "                if not np.isnan(auc_score):\n",
        "                    auc_labels[\"auc_%d\" % i] = auc_score\n",
        "                    relevant_labels.append(i)\n",
        "\n",
        "    #macro-AUC: just average the auc scores\n",
        "    aucs = []\n",
        "    for i in relevant_labels:\n",
        "        aucs.append(auc_labels['auc_%d' % i])\n",
        "    roc_auc['auc_macro'] = np.mean(aucs)\n",
        "\n",
        "    #micro-AUC: just look at each individual prediction\n",
        "    yhatmic = yhat_raw.ravel()\n",
        "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(ymic, yhatmic)\n",
        "    roc_auc[\"auc_micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
        "\n",
        "    return roc_auc\n",
        "\n",
        "def recall_at_k(yhat_raw, y, k):\n",
        "    #num true labels in top k predictions / num true labels\n",
        "    sortd = np.argsort(yhat_raw)[:,::-1]\n",
        "    topk = sortd[:,:k]\n",
        "\n",
        "    #get recall at k for each example\n",
        "    vals = []\n",
        "    for i, tk in enumerate(topk):\n",
        "        num_true_in_top_k = y[i,tk].sum()\n",
        "        denom = y[i,:].sum()\n",
        "        vals.append(num_true_in_top_k / float(denom))\n",
        "\n",
        "    vals = np.array(vals)\n",
        "    vals[np.isnan(vals)] = 0.\n",
        "\n",
        "    return np.mean(vals)\n",
        "\n",
        "def precision_at_k(yhat_raw, y, k):\n",
        "    #num true labels in top k predictions / k\n",
        "    sortd = np.argsort(yhat_raw)[:,::-1]\n",
        "    topk = sortd[:,:k]\n",
        "\n",
        "    #get precision at k for each example\n",
        "    vals = []\n",
        "    for i, tk in enumerate(topk):\n",
        "        if len(tk) > 0:\n",
        "            num_true_in_top_k = y[i,tk].sum()\n",
        "            denom = len(tk)\n",
        "            vals.append(num_true_in_top_k / float(denom))\n",
        "\n",
        "    return np.mean(vals)\n",
        "\n",
        "def all_metrics(yhat, y, k=8, yhat_raw=None, calc_auc=True):\n",
        "    \"\"\"\n",
        "        Inputs:\n",
        "            yhat: binary predictions matrix\n",
        "            y: binary ground truth matrix\n",
        "            k: for @k metrics\n",
        "            yhat_raw: prediction scores matrix (floats)\n",
        "        Outputs:\n",
        "            dict holding relevant metrics\n",
        "    \"\"\"\n",
        "    names = [\"acc\", \"prec\", \"rec\", \"f1\"]\n",
        "\n",
        "    #macro\n",
        "    macro = all_macro(yhat, y)\n",
        "\n",
        "    #micro\n",
        "    ymic = y.ravel()\n",
        "    yhatmic = yhat.ravel()\n",
        "    micro = all_micro(yhatmic, ymic)\n",
        "\n",
        "    metrics = {names[i] + \"_macro\": macro[i] for i in range(len(macro))}\n",
        "    metrics.update({names[i] + \"_micro\": micro[i] for i in range(len(micro))})\n",
        "\n",
        "    #AUC and @k\n",
        "    if yhat_raw is not None and calc_auc:\n",
        "        #allow k to be passed as int or list\n",
        "        if type(k) != list:\n",
        "            k = [k]\n",
        "        for k_i in k:\n",
        "            rec_at_k = recall_at_k(yhat_raw, y, k_i)\n",
        "            metrics['rec_at_%d' % k_i] = rec_at_k\n",
        "            prec_at_k = precision_at_k(yhat_raw, y, k_i)\n",
        "            metrics['prec_at_%d' % k_i] = prec_at_k\n",
        "            metrics['f1_at_%d' % k_i] = 2*(prec_at_k*rec_at_k)/(prec_at_k+rec_at_k)\n",
        "\n",
        "        roc_auc = auc_metrics(yhat_raw, y, ymic)\n",
        "        metrics.update(roc_auc)\n",
        "\n",
        "    return metrics\n",
        "\n"
      ],
      "metadata": {
        "id": "p4NZIzvI3Tka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Results\n",
        "\n",
        "This summary presents the results from the application of the MultiResCNN model equipped with a HierarchicalHyperbolic decoder, specifically designed to address the complexities of medical text classification. My experimental setup aims to evaluate the model's effectiveness across various hierarchical depths, with a specific focus on precision at depth 8 (prec_at_8) as the primary criterion. Below, I detail the configuration of my experiments, present a comprehensive summary of results across multiple depths, and compare these outcomes with existing benchmarks from the original paper.\n",
        "\n",
        "## Model Comparison, Training and Evaluation Summary\n",
        "\n",
        "### Configuration\n",
        "- **Model**: MultiResCNN with HierarchicalHyperbolic decoder\n",
        "- **Criterion**: Precision at depth 8 (prec_at_8)\n",
        "- **Batch size**: 8\n",
        "- **Learning rate**: 5e-05\n",
        "- **Dropout**: 0.2\n",
        "- **Filters sizes**: 3, 5, 9, 15, 19, 25\n",
        "\n",
        "### Results Summary (Depth 0 to 4)\n",
        "\n",
        "#### Depth 0 Results:\n",
        "- Best Macro AUC: 0.8921\n",
        "- Best Micro AUC: 0.9507\n",
        "- Best prec_at_8: 0.7849\n",
        "\n",
        "#### Depth 1 Results:\n",
        "- Best Macro AUC: 0.9032\n",
        "- Best Micro AUC: 0.9732\n",
        "- Best prec_at_8: 0.8130\n",
        "\n",
        "#### Depth 2 Results:\n",
        "- Best Macro AUC: 0.9157\n",
        "- Best Micro AUC: 0.9838\n",
        "- Best prec_at_8: 0.7992\n",
        "\n",
        "#### Depth 3 Results:\n",
        "- Best Macro AUC: 0.9335\n",
        "- Best Micro AUC: 0.9891\n",
        "- Best prec_at_8: 0.7641\n",
        "\n",
        "#### Depth 4 Results:\n",
        "- Best Macro AUC: 0.9461\n",
        "- Best Micro AUC: 0.9906\n",
        "- Best prec_at_8: 0.7394\n",
        "\n",
        "### Comparative Analysis with Paper\n",
        "\n",
        "#### Observations:\n",
        "- Increasing depth improves the Micro AUC consistently, suggesting better performance on the individual label predictions as the model becomes more specific in its hierarchy.\n",
        "- Macro AUC generally improves with depth, indicating improved average performance across all labels, particularly as the specificity of the hierarchy increases.\n",
        "- The precision at a threshold of 8 (prec_at_8) tends to decrease slightly with increased depth. This could suggest a trade-off where the model becomes more conservative or struggles with the specificity of deeper labels.\n",
        "\n",
        "#### Conclusion:\n",
        "The experiments demonstrate the viability of using hierarchical decoders in medical text classification. The results show significant improvements in AUC metrics as the depth increases, aligning well with theoretical expectations from the paper. However, the decline in prec_at_8 at higher depths may warrant further investigation or adjustments in model training or hyperparameters to balance the precision-recall trade-off effectively."
      ],
      "metadata": {
        "id": "gX6bCcZNuxmz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define metrics dictionary\n",
        "metrics = {\n",
        "    \"acc_macro\": [\n",
        "        0.0319410441138809, 0.03739311692629136, 0.04200764727082538, 0.041908939148518586, 0.04428193820820927,\n",
        "        0.04648494208681928, 0.04702845262416949, 0.051632401177169884, 0.04940818538863592, 0.05339134182512112,\n",
        "        0.05339318491330262, 0.053907763773604386, 0.05705621680566151, 0.05831238854021586, 0.05533569204532243,\n",
        "        0.05633576198223152, 0.056353274170392334, 0.05776788409498362, 0.05948067460477451, 0.05802529620301705,\n",
        "        0.05902107262307773, 0.061568241778608354, 0.06103727929906239, 0.05705621680566151\n",
        "    ],\n",
        "    \"prec_macro\": [\n",
        "        0.055050915080455315, 0.06191013370758759, 0.06751163951241014, 0.06825219903519515, 0.07192044409172237,\n",
        "        0.07335514190622429, 0.07580388564414706, 0.0786843241755169, 0.07845020073004967, 0.08210756743872959,\n",
        "        0.08178934588637381, 0.08272133651879061, 0.08661519010508072, 0.08759395613888937, 0.08528581434217886,\n",
        "        0.08734165756882176, 0.0868481832691611, 0.0875884866070976, 0.08884225647994876, 0.08884726693098187,\n",
        "        0.0895100500563429, 0.09168249059996848, 0.09048287944898398, 0.08661519010508072\n",
        "    ],\n",
        "    \"rec_macro\": [\n",
        "        0.03903634284502181, 0.04537442076745888, 0.05178045999616125, 0.05051695951123941, 0.053561232680709434,\n",
        "        0.05644434369605238, 0.05634899883781107, 0.0626907566083086, 0.0593062441239584, 0.06523472549072648,\n",
        "        0.06570519213770168, 0.06528156540655329, 0.06970809925349064, 0.07187939262886385, 0.06681296987560384,\n",
        "        0.0683895395592821, 0.0679721201210295, 0.07022182597546836, 0.07270862852140461, 0.07085275192101909,\n",
        "        0.07136283509443288, 0.07548352279060942, 0.07456319393673784, 0.06970809925349064\n",
        "    ],\n",
        "    \"f1_macro\": [\n",
        "        0.04568071048929844, 0.05236795679234704, 0.058608805837916084, 0.05806041934474095, 0.06139777120579582,\n",
        "        0.06379813945202562, 0.06464441666646722, 0.06978287529072004, 0.06754800853057143, 0.07270505319394327,\n",
        "        0.07287028737842399, 0.07297395213497786, 0.07724735442145901, 0.07896241489720131, 0.07492760147643744,\n",
        "        0.07671238461697089, 0.07625944422272245, 0.07794957583345839, 0.07996983270441176, 0.07883622566826701,\n",
        "        0.07941289715141815, 0.08279813854904816, 0.08175526202967179, 0.07724735442145901\n",
        "    ],\n",
        "    \"acc_micro\": [\n",
        "        0.3473671512153919, 0.3633028626413268, 0.37439456585942, 0.37417857358171946, 0.38079420654157947,\n",
        "        0.3870202993035994, 0.3847281649262428, 0.39313337663104325, 0.3887213780338526, 0.398876240086622,\n",
        "        0.3964927663305556, 0.398133200270039, 0.4015111886079616, 0.40275973557345224, 0.39399037751999644,\n",
        "        0.39903239994135636, 0.3968160723726711, 0.4004991004584748, 0.4022388492546824, 0.4019463028933866,\n",
        "        0.4015844352536832, 0.4042896214193165, 0.40274783708430223, 0.4015111886079616\n",
        "    ],\n",
        "    \"prec_micro\": [\n",
        "        0.7077547007496577, 0.7133915918752911, 0.6990350151640436, 0.7223159732324661, 0.717305524239004,\n",
        "        0.7096669021355176, 0.7192481960060373, 0.7087657672042115, 0.7187568999779161, 0.7026135367802429,\n",
        "        0.7000361215748971, 0.7053195361655624, 0.696933010492329, 0.6910009410133194, 0.7090571049136749,\n",
        "        0.7046913835956882, 0.7053357001148549, 0.6948947739401838, 0.6952380952380918, 0.693795930610405,\n",
        "        0.6991886409736273, 0.6891931684334478, 0.6868290770060258, 0.696933010492329\n",
        "    ],\n",
        "    \"rec_micro\": [\n",
        "        0.4055348214914429, 0.4253925779874642, 0.44634180691500447, 0.437046686853037, 0.4480318287444531,\n",
        "        0.4598267727624799, 0.4527145975635503, 0.46887543130765275, 0.45845363002605294, 0.47989578198718236,\n",
        "        0.47764241954791753, 0.4775720019716905, 0.4864446165762958, 0.49123301175973355, 0.46996690373917166,\n",
        "        0.47915639743679855, 0.47567072741356076, 0.48595169354270656, 0.48834589113442545, 0.48862756143933356,\n",
        "        0.4854587705091174, 0.49443701147806324, 0.4933455390465443, 0.4864446165762958\n",
        "    ],\n",
        "    \"f1_micro\": [\n",
        "        0.5156236010385867, 0.5329745467378335, 0.5448138040698776, 0.5445850790795598, 0.5515582332798729,\n",
        "        0.5580600363209035, 0.5556731995073336, 0.5643872772350637, 0.5598263037963775, 0.5702809564653436,\n",
        "        0.5678407735292248, 0.5695211303088172, 0.5729689379173037, 0.5742390879344739, 0.565269866813473,\n",
        "        0.5704405415601267, 0.5681722600723333, 0.5719376761147001, 0.573709463931169, 0.5734118376200783,\n",
        "        0.5730435144008953, 0.5757923654106336, 0.574226994242155, 0.5729689379173037\n",
        "    ],\n",
        "    \"rec_at_5\": [\n",
        "        0.28035160005894366, 0.28389498650038003, 0.2876526043394757, 0.28849394141515966, 0.28760356534531284,\n",
        "        0.290001134819842, 0.28888985466673245, 0.29138536051226804, 0.28951010152440354, 0.2905445111007091,\n",
        "        0.28922524982472425, 0.2908734395607854, 0.29163025434631956, 0.29136527694094994, 0.2907998533264755,\n",
        "        0.2908933890656855, 0.29084962284934807, 0.2899424620628628, 0.2901021192561756, 0.29038023806866486,\n",
        "        0.2890369089033346, 0.2891462930811932, 0.28974348362268615, 0.29163025434631956\n",
        "    ],\n",
        "    \"prec_at_5\": [\n",
        "        0.7981606376456163, 0.804659717964439, 0.8132434089515636, 0.8165542611894543, 0.8159411404046597,\n",
        "        0.8206008583690986, 0.819865113427345, 0.8253832004904966, 0.8188841201716739, 0.8220723482526058,\n",
        "        0.820232985898222, 0.82501532801962, 0.8268546903740037, 0.8239117106069895, 0.8250153280196199,\n",
        "        0.8245248313917843, 0.8261189454322502, 0.8244022072348252, 0.8224402207234826, 0.8226854690374004,\n",
        "        0.818638871857756, 0.8191293684855917, 0.8198651134273452, 0.8268546903740037\n",
        "    ],\n",
        "    \"f1_at_5\": [\n",
        "        0.41495238356175623, 0.41971038999133164, 0.4249839798175144, 0.42635417465888886, 0.4252978241290547,\n",
        "        0.4285516893011548, 0.4272372530992855, 0.4307151720312398, 0.4277814159024539, 0.4293456575002665,\n",
        "        0.42765393526743684, 0.43010567562531726, 0.43118299410192584, 0.4304926335182335, 0.4300252235155504,\n",
        "        0.4300607936528043, 0.43022944518004597, 0.4290040815583046, 0.4289124870479294, 0.4292497753359448,\n",
        "        0.4272312406565358, 0.4274175255580583, 0.42817003166105927, 0.43118299410192584\n",
        "    ],\n",
        "    \"rec_at_8\": [\n",
        "        0.38924594705722326, 0.3978040625441737, 0.39843560412660195, 0.40175624758191164, 0.40425926935326145,\n",
        "        0.4039384205015307, 0.40502899896068867, 0.40645029952173134, 0.40627602921723655, 0.4075762217442141,\n",
        "        0.40732932273703515, 0.4070230117222617, 0.4091276717648278, 0.4082164670945313, 0.4073553858489137,\n",
        "        0.4088743225810868, 0.4087653800194409, 0.4084985232875138, 0.40739297805348046, 0.4087075012222824,\n",
        "        0.40823227066987794, 0.4069017499549039, 0.4077689189210399, 0.4091276717648278\n",
        "    ],\n",
        "    \"prec_at_8\": [\n",
        "        0.7135959534028203, 0.726241569589209, 0.7291538933169834, 0.7341354996934396, 0.7394236664622931,\n",
        "        0.7397302268546904, 0.7415695892090742, 0.7454015941140405, 0.7437155119558553, 0.7450183936235438,\n",
        "        0.7460147148988351, 0.7450183936235438, 0.7481606376456161, 0.7461679950950337, 0.7456315144083384,\n",
        "        0.7466278356836297, 0.747164316370325, 0.7472409564684243, 0.7452483139178419, 0.7477774371551196,\n",
        "        0.746474555487431, 0.7440220723482526, 0.7456315144083384, 0.7481606376456161\n",
        "    ],\n",
        "    \"f1_at_8\": [\n",
        "        0.5037246636759363, 0.5140393566099682, 0.5152954557375189, 0.5193162540021707, 0.5227303158692296,\n",
        "        0.5225385169448525, 0.5239099218785541, 0.5260549604781564, 0.5254887088238334, 0.5269012677213343,\n",
        "        0.5269436675538489, 0.5264387702629726, 0.5289835165482188, 0.527723774519559, 0.52686984246768,\n",
        "        0.5283883692502641, 0.5284316281032707, 0.5282277409468799, 0.5268055762206347, 0.5285364948010001,\n",
        "        0.5278136335229507, 0.5260884819253216, 0.5272156100481007, 0.5289835165482188\n",
        "    ],\n",
        "    \"rec_at_15\": [\n",
        "        0.541341411179512, 0.5526087771865853, 0.555893346821313, 0.5621222894765862, 0.5665070377113649,\n",
        "        0.5668091792442521, 0.5714924498082927, 0.5709536406846468, 0.5725970986582951, 0.5742791329872476,\n",
        "        0.5712066287427464, 0.572907029663427, 0.5740970019525167, 0.573122776841011, 0.5749192196842763,\n",
        "        0.573275095914807, 0.5750569879411549, 0.5744172529608215, 0.5735556622993224, 0.57312359052784,\n",
        "        0.5738734210780555, 0.5729044608861602, 0.5752298550121455, 0.5740970019525167\n",
        "    ],\n",
        "    \"prec_at_15\": [\n",
        "        0.557653791130186, 0.56856734109953, 0.5731453096259963, 0.5789903944410382, 0.5842632331902718,\n",
        "        0.5843041079092581, 0.5882280809319436, 0.5884324545268751, 0.5896995708154507, 0.5912528101369302,\n",
        "        0.5893316983445739, 0.5909258123850398, 0.5919068056407113, 0.5908849376660535, 0.592560801144492,\n",
        "        0.5911710606989576, 0.5931330472103005, 0.5919885550786839, 0.5914163090128756, 0.5910893112609851,\n",
        "        0.5921111792356427, 0.5915798078888207, 0.5926425505824647, 0.5919068056407113\n",
        "    ],\n",
        "    \"f1_at_15\": [\n",
        "        0.549376538870366, 0.5604744838724066, 0.5643875213014936, 0.5704316684847978, 0.5752481478669984,\n",
        "        0.5754236972662531, 0.5797395115584528, 0.5795612929924389, 0.5810225086196825, 0.5826423774737066,\n",
        "        0.5801276265774078, 0.5817769351294219, 0.5828658883285056, 0.5818683365206184, 0.5836067210257587,\n",
        "        0.5820855599022157, 0.5839551670767208, 0.5830705527162917, 0.5823490713315994, 0.5819678305780747,\n",
        "        0.5828496671312821, 0.5820923820056758, 0.5838063932540826, 0.5828658883285056\n",
        "    ],\n",
        "    \"auc_macro\": [\n",
        "        0.9389798372481776, 0.9426919790688367, 0.9444346256170416, 0.9452248935126247, 0.9461177668384458,\n",
        "        0.946386139568928, 0.9472251274864014, 0.9475613571256425, 0.9476326878967255, 0.948315871548033,\n",
        "        0.9488060366634748, 0.9486536474750279, 0.9483379537025396, 0.948229719222197, 0.9482253933497689,\n",
        "        0.9480277528948664, 0.9479714660764048, 0.9480112307297707, 0.9479350898081624, 0.948007197996098,\n",
        "        0.9472651179102068, 0.9471547056773878, 0.9468984523368007, 0.9483379537025396\n",
        "    ],\n",
        "    \"auc_micro\": [\n",
        "        0.9891575495614335, 0.9898036620730503, 0.9901548782452172, 0.9903913315843522, 0.9906283489987753,\n",
        "        0.9906259686609908, 0.9906632586197587, 0.9908049935199525, 0.9907703235917504, 0.990943530504026,\n",
        "        0.9911151811061722, 0.9910326796902206, 0.9909769248165419, 0.9910135257844908, 0.9909313494990228,\n",
        "        0.9909053133988264, 0.9908204330379967, 0.9907813589190633, 0.9907305478876433, 0.9906805755524407,\n",
        "        0.9907075288365684, 0.9906649485616948, 0.9906066916520845, 0.9909769248165419\n",
        "    ],\n",
        "    \"loss_dev\": [\n",
        "        0.005253945010753347, 0.005109813651124245, 0.005071664897370673, 0.004988505242020263, 0.004949123402545686,\n",
        "        0.0049383173346808406, 0.0049184202342902284, 0.004899668522195686, 0.00489568907060834, 0.004892333869703553,\n",
        "        0.004887816087151652, 0.004871796344769925, 0.004880910685252664, 0.0048931323136100205, 0.004885588675005199,\n",
        "        0.004892962677285799, 0.004903879789932466, 0.0049172262466122335, 0.004924529547855066, 0.004941300906294187,\n",
        "        0.00493478821128379, 0.004960395178039131, 0.004962928907447971, 0.004880910685252664\n",
        "    ],\n",
        "    \"acc_macro_te\": [0.06390121460628688],\n",
        "    \"prec_macro_te\": [0.10461532414484478],\n",
        "    \"rec_macro_te\": [0.07985898124468153],\n",
        "    \"f1_macro_te\": [0.09057600939218684],\n",
        "    \"acc_micro_te\": [0.3955432510924729],\n",
        "    \"prec_micro_te\": [0.6912204145520071],\n",
        "    \"rec_micro_te\": [0.48043385092143787],\n",
        "    \"f1_micro_te\": [0.5668663451065805],\n",
        "    \"rec_at_5_te\": [0.2803638169377092],\n",
        "    \"prec_at_5_te\": [0.8225978647686834],\n",
        "    \"f1_at_5_te\": [0.4181952664294828],\n",
        "    \"rec_at_8_te\": [0.39540801202221154],\n",
        "    \"prec_at_8_te\": [0.749814650059312],\n",
        "    \"f1_at_8_te\": [0.5177730584307586],\n",
        "    \"rec_at_15_te\": [0.5592055521973873],\n",
        "    \"prec_at_15_te\": [0.5969553183076315],\n",
        "    \"f1_at_15_te\": [0.5774641521392625],\n",
        "    \"auc_macro_te\": [0.9477779712892075],\n",
        "    \"auc_micro_te\": [0.9906868448470423],\n",
        "    \"loss_test_te\": [0.005061819953743313],\n",
        "    \"loss_tr\": [\n",
        "        0.0049190428767240885, 0.004519941277875372, 0.004376297469944861, 0.0042810088326047544, 0.004205600803480651,\n",
        "        0.00414191668303582, 0.004082608513833841, 0.004032923659440114, 0.003986341197493315, 0.003944799933236713,\n",
        "        0.0039041667736946523, 0.0038645350913909847, 0.0038302744528761153, 0.00379381276647992,\n",
        "        0.0037617698310244414, 0.0037301000024208427, 0.003695994527652947, 0.0036657694461564192,\n",
        "        0.003637516189191712, 0.0036060613572827015, 0.0035780908498906803, 0.0035523561911449796,\n",
        "        0.003524543843813684, float('nan')\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Plotting the graphs\n",
        "epochs = list(range(1, 25))\n",
        "plt.figure(figsize=(18, 12))\n",
        "\n",
        "# Macro and Micro Accuracy\n",
        "plt.subplot(3, 2, 1)\n",
        "plt.plot(epochs, metrics[\"acc_macro\"], label='Macro Accuracy')\n",
        "plt.plot(epochs, metrics[\"acc_micro\"], label='Micro Accuracy')\n",
        "plt.title('Macro and Micro Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "# Macro and Micro Precision\n",
        "plt.subplot(3, 2, 2)\n",
        "plt.plot(epochs, metrics[\"prec_macro\"], label='Macro Precision')\n",
        "plt.plot(epochs, metrics[\"prec_micro\"], label='Micro Precision')\n",
        "plt.title('Macro and Micro Precision')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Precision')\n",
        "plt.legend()\n",
        "\n",
        "# Macro and Micro Recall\n",
        "plt.subplot(3, 2, 3)\n",
        "plt.plot(epochs, metrics[\"rec_macro\"], label='Macro Recall')\n",
        "plt.plot(epochs, metrics[\"rec_micro\"], label='Micro Recall')\n",
        "plt.title('Macro and Micro Recall')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Recall')\n",
        "plt.legend()\n",
        "\n",
        "# Macro and Micro F1-Score\n",
        "plt.subplot(3, 2, 4)\n",
        "plt.plot(epochs, metrics[\"f1_macro\"], label='Macro F1-Score')\n",
        "plt.plot(epochs, metrics[\"f1_micro\"], label='Micro F1-Score')\n",
        "plt.title('Macro and Micro F1-Score')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('F1-Score')\n",
        "plt.legend()\n",
        "\n",
        "# AUC Macro and Micro\n",
        "plt.subplot(3, 2, 5)\n",
        "plt.plot(epochs, metrics[\"auc_macro\"], label='AUC Macro')\n",
        "plt.plot(epochs, metrics[\"auc_micro\"], label='AUC Micro')\n",
        "plt.title('AUC Macro and Micro')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('AUC')\n",
        "plt.legend()\n",
        "\n",
        "# Development and Training Loss\n",
        "plt.subplot(3, 2, 6)\n",
        "plt.plot(epochs, metrics[\"loss_dev\"], label='Development Loss')\n",
        "plt.title('Development and Training Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "wF3dNiEt54JE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Discussion\n",
        "\n",
        "## Discussion and Future Plan\n",
        "\n",
        "### Reproducibility Assessment\n",
        "At this stage, having tested only one of the three proposed hypotheses (`MultiResCNN with HiCuA`), it is premature to conclusively declare the paper's reproducibility. The initial results align with the paper's claims (as noted in the Results section), suggesting positive reproducibility indications. The ongoing experiments with `RAC with HiCuA` and `LAAT with HiCuA and ASL` will provide a comprehensive reproducibility verdict.\n",
        "\n",
        "### Encountered Challenges\n",
        "#### What Was Easy:\n",
        "- Although the initial setup required some hours to complete, the process will be much more straightforward for future reproducers thanks to the `environment.yml` file that I created.\n",
        "\n",
        "#### What Was Difficult:\n",
        "- The model training, particularly for the RAC model, is resource-intensive and time-consuming. While not inherently difficult, the demand for substantial computational resources can be a limiting factor.\n",
        "- Juggling this project on my own while keeping up with my other responsibilities was tough. Not having a team meant I had to tackle all the model training complexities solo, which made for a pretty intense and lonely ride.\n",
        "\n",
        "### Suggestions for Improvement\n",
        "- For the original authors: Including environment setup files (e.g., `environment.yml`) could further simplify reproduction efforts.\n",
        "- For future reproducers: Utilize the provided `environment.yml` to ease the initial setup process. Adequate computing resources, akin to the 4 NVIDIA Tesla V100 GPUs used in the paper, are recommended.\n",
        "\n",
        "### Next Phase\n",
        "The following objectives are set for the next phase:\n",
        "- Optimize the code for Google Colab execution.\n",
        "- Refine current workflows and document the setup comprehensively.\n",
        "- Complete the reproduction of `RAC with HiCuA` and `LAAT with HiCuA and ASL`.\n",
        "- Prepare and finalize the documentation for the completed reproducibility study."
      ],
      "metadata": {
        "id": "qH75TNU71eRH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# References\n",
        "\n",
        "1. Weiming Ren, Ruijing Zeng, Tongzi Wu, Tianshu Zhu, Rahul G. Krishnan (2022). HiCu: Leveraging Hierarchy for Curriculum Learning in Automated ICD Coding. Proceedings of the 7th Machine Learning for Healthcare Conference, PMLR 182:198-223 https://arxiv.org/pdf/2208.02301.pdf\n",
        "\n"
      ],
      "metadata": {
        "id": "SHMI2chl9omn"
      }
    }
  ]
}